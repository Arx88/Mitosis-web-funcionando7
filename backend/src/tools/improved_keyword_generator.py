"""
ðŸ§  GENERADOR INTELIGENTE DE KEYWORDS - SOLUCIÃ“N COMPLETA V2.0
Reemplaza la lÃ³gica destructiva de _extract_clean_keywords_static()
con un sistema inteligente que preserva el contexto esencial

RESUELVE: 
- Keywords inÃºtiles como "REALIZA INFORME"
- PÃ©rdida de contexto importante
- BÃºsquedas genÃ©ricas sin resultados

IMPLEMENTA:
- PreservaciÃ³n de entidades nombradas (personas, lugares)
- ExtracciÃ³n inteligente de conceptos principales
- MÃºltiples variantes de bÃºsqueda especÃ­ficas
- Contexto temporal y geogrÃ¡fico automÃ¡tico
"""

import re
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class IntelligentKeywordGenerator:
    """ðŸŽ¯ Generador inteligente de keywords y tÃ©rminos de bÃºsqueda"""
    
    def __init__(self):
        # Entidades importantes que SIEMPRE deben preservarse
        self.preserve_entities = {
            'personas': ['milei', 'javier', 'biden', 'musk', 'elon', 'trump', 'cristina', 'massa', 
                        'alberto', 'fernÃ¡ndez', 'macri', 'mauricio', 'cristiano', 'messi', 'lionel'],
            'lugares': ['argentina', 'buenos', 'aires', 'cÃ³rdoba', 'mendoza', 'espaÃ±a', 'madrid', 
                       'barcelona', 'valencia', 'mÃ©xico', 'colombia', 'chile', 'usa', 'eeuu'],
            'organizaciones': ['fifa', 'onu', 'oea', 'mercosur', 'gobierno', 'congress', 'senate'],
            'tecnologia': ['inteligencia', 'artificial', 'blockchain', 'bitcoin', 'crypto', 'tesla', 
                          'apple', 'google', 'microsoft', 'meta', 'openai', 'chatgpt'],
            'conceptos': ['economÃ­a', 'polÃ­tica', 'inflaciÃ³n', 'dÃ³lar', 'peso', 'elecciones', 
                         'democracia', 'libertad', 'socialismo', 'capitalismo', 'crisis'],
            'temporal': ['2024', '2025', 'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio',
                        'actual', 'reciente', 'nuevo', 'Ãºltima', 'Ãºltimo'],
            'musica': ['arctic', 'monkeys', 'banda', 'mÃºsica', 'rock', 'discografÃ­a', 'Ã¡lbum', 
                      'canciÃ³n', 'concierto', 'gira', 'festival'],
            'anime_manga': ['attack', 'titan', 'shingeki', 'kyojin', 'eren', 'mikasa', 'armin', 'levi', 
                           'anime', 'manga', 'naruto', 'one', 'piece', 'dragon', 'ball', 'studio', 
                           'ghibli', 'miyazaki', 'otaku', 'cosplay'],
            'entretenimiento': ['netflix', 'disney', 'marvel', 'dc', 'comics', 'superhero', 'movie', 
                               'film', 'serie', 'temporada', 'episodio', 'actor', 'actress', 'director']
        }
        
        # Palabras meta que deben eliminarse COMPLETAMENTE
        self.meta_words = {
            'instrucciones': ['buscar', 'informaciÃ³n', 'sobre', 'acerca', 'utilizar', 'herramienta', 
                             'web_search', 'realizar', 'generar', 'crear', 'obtener', 'necesario',
                             'completar', 'especÃ­fico', 'datos', 'anÃ¡lisis', 'informe', 'recopilar',
                             'desarrollar', 'estrategia', 'bÃºsqueda', 'actual', 'actuales', 'web'],
            'conectores': ['para', 'con', 'por', 'desde', 'hasta', 'durante', 'mediante', 'segÃºn',
                          'ante', 'bajo', 'contra', 'entre', 'hacia', 'segÃºn', 'sin', 'tras'],
            'articulos': ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas'],
            'pronombres': ['que', 'cual', 'quien', 'donde', 'cuando', 'como', 'este', 'esta', 'ese', 'esa']
        }
        
        # Patrones problemÃ¡ticos que indican queries mal formados
        self.problematic_patterns = [
            r'\brealiza\s+informe\b',
            r'\butilizar\s+herramienta\b', 
            r'\bweb_search\s+para\b',
            r'\binformaciÃ³n\s+especÃ­fica\s+sobre\b',
            r'\bgenera\s+(un|una)\s+(anÃ¡lisis|informe|reporte)\b',
            r'\brecopilar\s+datos\s+de\s+mercado\b',
            r'\brealizar\s+una\s+bÃºsqueda\s+web\b',
            r'\bdesarrollar\s+una\s+estrategia\b',
            r'\bobtener\s+datos\s+actuales\b'
        ]
    
    def get_intelligent_keywords(self, query_text: str) -> str:
        """ðŸŽ¯ FUNCIÃ“N PRINCIPAL: Generar keywords inteligentes"""
        
        if not query_text or len(query_text.strip()) < 3:
            return "informaciÃ³n actualizada"
        
        print(f"ðŸ§  INTELLIGENT GENERATOR INPUT: '{query_text}'")
        
        # 1. Detectar si es query problemÃ¡tico
        if self._is_problematic_query(query_text):
            print("âš ï¸ PROBLEMATIC QUERY detectado - aplicando correcciÃ³n especial")
            return self._fix_problematic_query(query_text)
        
        # 2. Extraer entidades importantes (nombres propios, conceptos clave)
        entities = self._extract_important_entities(query_text)
        
        # 3. Extraer conceptos principales 
        concepts = self._extract_main_concepts(query_text)
        
        # 4. Combinar y optimizar
        result = self._combine_and_optimize(entities, concepts, query_text)
        
        print(f"âœ… INTELLIGENT RESULT: '{query_text}' â†’ '{result}'")
        return result
    
    def get_multiple_search_variants(self, query_text: str, count: int = 3) -> List[str]:
        """ðŸ”„ Generar mÃºltiples variantes de bÃºsqueda para diversidad"""
        
        base_keywords = self.get_intelligent_keywords(query_text)
        variants = [base_keywords]
        
        # Variante 1: Con contexto temporal
        if '2025' not in base_keywords and '2024' not in base_keywords:
            variants.append(f"{base_keywords} 2025 actualidad")
        
        # Variante 2: Con especificidad geogrÃ¡fica si aplicable
        if any(lugar in query_text.lower() for lugar in self.preserve_entities['lugares']):
            variants.append(f"{base_keywords} noticias recientes")
        else:
            variants.append(f"{base_keywords} informaciÃ³n completa")
        
        # Variante 3: Con enfoque especÃ­fico
        if any(persona in query_text.lower() for persona in self.preserve_entities['personas']):
            variants.append(f"{base_keywords} biografÃ­a trayectoria")
        elif any(tech in query_text.lower() for tech in self.preserve_entities['tecnologia']):
            variants.append(f"{base_keywords} definiciÃ³n caracterÃ­sticas")
        else:
            variants.append(f"{base_keywords} guÃ­a completa")
        
        return variants[:count]
    
    def _is_problematic_query(self, query_text: str) -> bool:
        """ðŸš¨ Detectar queries problemÃ¡ticos que generan keywords inÃºtiles"""
        
        query_lower = query_text.lower()
        
        # ðŸŽ¯ FIRST CHECK: Si contiene temas especÃ­ficos conocidos, NUNCA es problemÃ¡tico
        specific_topics = [
            'attack on titan', 'shingeki no kyojin', 'eren jaeger', 'mikasa ackerman',
            'arctic monkeys', 'alex turner', 'the strokes', 'coldplay',
            'inteligencia artificial', 'machine learning', 'chatgpt', 'openai',
            'javier milei', 'argentina presidente', 'elecciones argentina',
            'netflix series', 'disney plus', 'marvel movies', 'dc comics',
            'bitcoin price', 'cryptocurrency', 'blockchain technology',
            'climate change', 'global warming', 'renewable energy'
        ]
        
        for topic in specific_topics:
            if topic in query_lower:
                print(f"âœ… SPECIFIC TOPIC DETECTED: '{topic}' - NOT problematic")
                return False
        
        # ðŸŽ¯ SECOND CHECK: Si tiene nombres propios claros, probablemente no es problemÃ¡tico
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', query_text)
        if len(proper_nouns) >= 2:  # Dos o mÃ¡s nombres propios = tema especÃ­fico
            print(f"âœ… PROPER NOUNS DETECTED: {proper_nouns} - NOT problematic")
            return False
        
        # Verificar patrones problemÃ¡ticos conocidos
        for pattern in self.problematic_patterns:
            if re.search(pattern, query_lower):
                return True
        
        # Verificar si tiene muchas palabras meta vs. pocas entidades
        meta_count = sum(1 for category in self.meta_words.values() 
                        for word in category if word in query_lower)
        
        entity_count = sum(1 for category in self.preserve_entities.values()
                          for entity in category if entity in query_lower)
        
        # ðŸŽ¯ AJUSTE CRÃTICO: Solo es problemÃ¡tico si hay MUCHAS mÃ¡s palabras meta que entidades
        # Y no contiene temas especÃ­ficos obvios
        if meta_count > 5 and entity_count < 1:
            # DOUBLE CHECK: Buscar entidades que no estÃ©n en la lista pero que sean obvias
            potential_entities = re.findall(r'\b[a-zA-Z]{4,}\b', query_text)
            non_meta_entities = []
            
            for word in potential_entities:
                word_lower = word.lower()
                if not any(word_lower in metas for metas in self.meta_words.values()):
                    non_meta_entities.append(word_lower)
            
            # Si hay entidades potenciales no-meta, NO es problemÃ¡tico
            if len(non_meta_entities) >= 2:
                print(f"âœ… POTENTIAL ENTITIES FOUND: {non_meta_entities} - NOT problematic")
                return False
                
            return True
        
        return False
    
    def _fix_problematic_query(self, query_text: str) -> str:
        """ðŸ”§ Reparar queries problemÃ¡ticos extrayendo el tema real"""
        
        query_lower = query_text.lower()
        
        # Buscar patrones especÃ­ficos de tema
        theme_patterns = [
            r'sobre\s+"([^"]+)"',  # sobre "tema"
            r'sobre\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+?)(?:\s+en\s|\s+con\s|$)',  # sobre tema
            r'informaciÃ³n.*?([a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,}(?:\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,})*)',  # informaciÃ³n tema
            r'anÃ¡lisis.*?([a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,}(?:\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,})*)',  # anÃ¡lisis tema
            r'mercado\s+objetivo.*?(redes\s+sociales|social\s+media|marketing)',  # mercado + marketing
            r'tendencias\s+de\s+(redes\s+sociales|social\s+media|marketing)',  # tendencias marketing
            r'estrategia\s+de\s+(marketing|redes\s+sociales|social\s+media)',  # estrategia marketing
            r'comportamiento\s+de\s+la\s+audiencia',  # comportamiento audiencia
        ]
        
        for pattern in theme_patterns:
            match = re.search(pattern, query_text, re.IGNORECASE)
            if match:
                theme = match.group(1).strip()
                print(f"ðŸ”§ TEMA EXTRAÃDO DE QUERY PROBLEMÃTICO: '{theme}'")
                return self._clean_and_enhance_theme(theme)
        
        # Buscar conceptos especÃ­ficos del contexto de marketing
        marketing_concepts = ['marketing', 'redes sociales', 'social media', 'audiencia', 
                             'mercado', 'tendencias', 'comportamiento', 'digital', 'contenido']
        
        found_concepts = []
        for concept in marketing_concepts:
            if concept in query_lower:
                found_concepts.append(concept)
        
        if found_concepts:
            result = ' '.join(found_concepts[:3]) + ' 2025'
            print(f"ðŸ”§ CONCEPTOS MARKETING EXTRAÃDOS: '{result}'")
            return result
        
        # Si no se encuentra patrÃ³n, usar extracciÃ³n de entidades de emergencia
        words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±A-ZÃÃ‰ÃÃ“ÃšÃ‘]{4,}\b', query_text)
        significant_words = []
        
        for word in words:
            word_lower = word.lower()
            # Incluir si es entidad importante o no es palabra meta
            if (any(word_lower in entities for entities in self.preserve_entities.values()) or
                not any(word_lower in metas for metas in self.meta_words.values())):
                significant_words.append(word_lower)
        
        if significant_words:
            result = ' '.join(significant_words[:4])
            print(f"ðŸ”§ EMERGENCIA - Palabras significativas extraÃ­das: '{result}'")
            return result
        
        # Ãšltimo recurso
        return "marketing digital redes sociales 2025"
    
    def _clean_and_enhance_theme(self, theme: str) -> str:
        """âœ¨ Limpiar y mejorar tema extraÃ­do"""
        
        # Remover comillas y espacios extra
        clean_theme = re.sub(r'["\']', '', theme).strip()
        
        # Si el tema es muy corto, agregarlo contexto relevante
        if len(clean_theme.split()) < 2:
            if any(keyword in clean_theme.lower() for keyword in ['marketing', 'social', 'redes']):
                return f"{clean_theme} estrategias marketing digital 2025"
            elif 'inteligencia' in clean_theme.lower():
                return f"{clean_theme} tendencias aplicaciones 2025"
            else:
                return f"{clean_theme} informaciÃ³n completa actualizada 2025"
        
        # Si ya es un buen tema, agregar contexto temporal
        if '2024' not in clean_theme and '2025' not in clean_theme:
            return f"{clean_theme} 2025"
        
        return clean_theme
    
    def _extract_important_entities(self, query_text: str) -> List[str]:
        """ðŸ·ï¸ Extraer entidades importantes (nombres propios, conceptos clave)"""
        
        entities = []
        query_lower = query_text.lower()
        
        # Buscar todas las entidades de alta prioridad
        for category, entity_list in self.preserve_entities.items():
            for entity in entity_list:
                if entity in query_lower:
                    entities.append(entity)
        
        # Buscar nombres propios adicionales (Capitalizados)
        proper_nouns = re.findall(r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{2,}(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)*\b', query_text)
        for noun in proper_nouns:
            if len(noun) > 3:
                entities.append(noun.lower())
        
        # Remover duplicados manteniendo orden
        seen = set()
        unique_entities = []
        for entity in entities:
            if entity not in seen:
                seen.add(entity)
                unique_entities.append(entity)
        
        return unique_entities[:6]  # MÃ¡ximo 6 entidades mÃ¡s importantes
    
    def _extract_main_concepts(self, query_text: str) -> List[str]:
        """ðŸ’¡ Extraer conceptos principales del texto"""
        
        concepts = []
        
        # Extraer palabras significativas (4+ caracteres)
        words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±A-ZÃÃ‰ÃÃ“ÃšÃ‘]{4,}\b', query_text)
        
        for word in words:
            word_lower = word.lower()
            
            # Incluir si NO es palabra meta
            is_meta = any(word_lower in meta_category for meta_category in self.meta_words.values())
            
            if not is_meta and len(word_lower) >= 4:
                concepts.append(word_lower)
        
        return concepts[:8]  # MÃ¡ximo 8 conceptos
    
    def _combine_and_optimize(self, entities: List[str], concepts: List[str], original_query: str) -> str:
        """âš¡ Combinar y optimizar entidades y conceptos"""
        
        # 1. Priorizar entidades (son mÃ¡s importantes)
        important_terms = entities[:3]  # Top 3 entidades
        
        # 2. Agregar conceptos que no sean repetitivos
        for concept in concepts:
            if (concept not in important_terms and 
                len(important_terms) < 6 and
                not any(concept in term for term in important_terms)):  # Evitar redundancia
                important_terms.append(concept)
        
        # 3. Si muy pocos tÃ©rminos, agregar contexto inteligente
        if len(important_terms) < 2:
            # Agregar contexto basado en tipo de consulta
            if any(persona in original_query.lower() for persona in self.preserve_entities['personas']):
                important_terms.append('biografÃ­a')
            elif any(tech in original_query.lower() for tech in self.preserve_entities['tecnologia']):
                important_terms.append('informaciÃ³n')
            else:
                important_terms.append('actualidad')
        
        # 4. Construir resultado final
        result = ' '.join(important_terms[:5])  # MÃ¡ximo 5 tÃ©rminos
        
        # 5. Agregar aÃ±o si no estÃ¡ presente y el resultado es corto
        if ('2024' not in result and '2025' not in result and 
            len(result.split()) < 4):
            result += ' 2025'
        
        return result

    def detect_granular_search_needs(self, query_text: str) -> List[Dict[str, str]]:
        """
        ðŸŽ¯ DETECTOR DE NECESIDAD DE BÃšSQUEDAS GRANULARES MÃšLTIPLES
        
        Detecta si una consulta necesita mÃºltiples bÃºsquedas especÃ­ficas
        para obtener informaciÃ³n completa sobre un tema
        """
        query_lower = query_text.lower()
        searches = []
        
        # ðŸŽ¬ PATRÃ“N: ANIME/MANGA (Attack on Titan, etc.)
        anime_patterns = [
            (r'attack\s+on\s+titan|shingeki\s+no\s+kyojin', 'Attack on Titan'),
            (r'naruto', 'Naruto'),
            (r'one\s+piece', 'One Piece'),
            (r'dragon\s+ball', 'Dragon Ball'),
            (r'demon\s+slayer|kimetsu\s+no\s+yaiba', 'Demon Slayer')
        ]
        
        for pattern, anime_name in anime_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{anime_name} trama historia argumento", "category": "trama"},
                    {"query": f"{anime_name} personajes principales protagonistas", "category": "personajes"},
                    {"query": f"{anime_name} contexto histÃ³rico mundo ficciÃ³n", "category": "contexto"},
                    {"query": f"{anime_name} recepciÃ³n crÃ­tica reseÃ±as puntuaciÃ³n", "category": "recepciÃ³n_crÃ­tica"},
                    {"query": f"{anime_name} mangaka autor Hajime Isayama creador", "category": "autor_creador"}
                ])
                break
        
        # ðŸŽµ PATRÃ“N: BANDAS/MÃšSICA
        music_patterns = [
            (r'arctic\s+monkeys', 'Arctic Monkeys'),
            (r'coldplay', 'Coldplay'),
            (r'radiohead', 'Radiohead'),
            (r'the\s+beatles', 'The Beatles')
        ]
        
        for pattern, band_name in music_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{band_name} historia formaciÃ³n miembros banda", "category": "historia"},
                    {"query": f"{band_name} discografÃ­a Ã¡lbumes completa", "category": "discografÃ­a"},
                    {"query": f"{band_name} estilo musical evoluciÃ³n gÃ©neros", "category": "estilo_musical"},
                    {"query": f"{band_name} premios reconocimientos Grammy awards", "category": "premios"},
                    {"query": f"{band_name} conciertos giras 2024 2025 fechas", "category": "tours_recientes"}
                ])
                break
        
        # ðŸ‘¤ PATRÃ“N: POLÃTICOS/FIGURAS PÃšBLICAS
        politician_patterns = [
            (r'javier\s+milei|milei', 'Javier Milei'),
            (r'donald\s+trump|trump', 'Donald Trump'),
            (r'joe\s+biden|biden', 'Joe Biden'),
            (r'elon\s+musk|musk', 'Elon Musk')
        ]
        
        for pattern, person_name in politician_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{person_name} biografÃ­a vida personal historia", "category": "biografÃ­a"},
                    {"query": f"{person_name} trayectoria carrera profesional polÃ­tica", "category": "trayectoria"},
                    {"query": f"{person_name} posiciones polÃ­ticas ideologÃ­a propuestas", "category": "ideologÃ­a"},
                    {"query": f"{person_name} declaraciones pÃºblicas entrevistas recientes", "category": "declaraciones"},
                    {"query": f"{person_name} noticias actualidad 2024 2025", "category": "noticias_recientes"}
                ])
                break
        
        # ðŸ”¬ PATRÃ“N: TECNOLOGÃA/CIENCIA
        tech_patterns = [
            (r'inteligencia\s+artificial|artificial\s+intelligence|AI', 'Inteligencia Artificial'),
            (r'machine\s+learning|aprendizaje\s+automÃ¡tico', 'Machine Learning'),
            (r'blockchain|cadena\s+de\s+bloques', 'Blockchain'),
            (r'chatgpt|gpt', 'ChatGPT')
        ]
        
        for pattern, tech_name in tech_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{tech_name} definiciÃ³n conceptos bÃ¡sicos explicaciÃ³n", "category": "conceptos"},
                    {"query": f"{tech_name} aplicaciones usos prÃ¡cticos ejemplos", "category": "aplicaciones"},
                    {"query": f"{tech_name} ventajas beneficios impacto positivo", "category": "ventajas"},
                    {"query": f"{tech_name} desventajas riesgos limitaciones", "category": "desventajas"},
                    {"query": f"{tech_name} tendencias futuro 2025 innovaciones", "category": "tendencias"}
                ])
                break
        
        # ðŸ† PATRÃ“N: DEPORTES/EQUIPOS
        sports_patterns = [
            (r'selecciÃ³n\s+argentina|argentina\s+fÃºtbol', 'SelecciÃ³n Argentina'),
            (r'real\s+madrid', 'Real Madrid'),
            (r'barcelona\s+fc|fc\s+barcelona', 'FC Barcelona'),
            (r'manchester\s+united', 'Manchester United')
        ]
        
        for pattern, team_name in sports_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{team_name} plantilla jugadores actual 2025", "category": "plantilla"},
                    {"query": f"{team_name} historia tÃ­tulos logros trofeos", "category": "historia"},
                    {"query": f"{team_name} estadÃ­sticas temporada 2024-2025 resultados", "category": "estadÃ­sticas"},
                    {"query": f"{team_name} Ãºltimos partidos resultados calendario", "category": "resultados_recientes"},
                    {"query": f"{team_name} fichajes transferencias mercado", "category": "transferencias"}
                ])
                break
        
        # ðŸ“º PATRÃ“N: ENTRETENIMIENTO/SERIES/PELÃCULAS
        entertainment_patterns = [
            (r'netflix\s+series|serie\s+netflix', 'Netflix Series'),
            (r'marvel\s+movies|pelÃ­culas\s+marvel', 'Marvel Movies'),
            (r'game\s+of\s+thrones|juego\s+de\s+tronos', 'Game of Thrones'),
            (r'stranger\s+things', 'Stranger Things')
        ]
        
        for pattern, content_name in entertainment_patterns:
            if re.search(pattern, query_lower):
                searches.extend([
                    {"query": f"{content_name} trama resumen historia", "category": "trama"},
                    {"query": f"{content_name} reparto actores personajes", "category": "reparto"},
                    {"query": f"{content_name} crÃ­ticas reseÃ±as puntuaciÃ³n IMDB", "category": "crÃ­ticas"},
                    {"query": f"{content_name} temporadas episodios disponibles", "category": "temporadas"},
                    {"query": f"{content_name} premios nominaciones Emmy Oscar", "category": "premios"}
                ])
                break
        
        print(f"ðŸŽ¯ GRANULAR SEARCH DETECTION: {len(searches)} bÃºsquedas especÃ­ficas detectadas")
        if searches:
            categories = [s['category'] for s in searches]
            print(f"   ðŸ“Š CategorÃ­as: {', '.join(categories)}")
        
        return searches

# Funciones pÃºblicas para usar desde unified_web_search_tool.py
def get_intelligent_keywords(query_text: str) -> str:
    """ðŸŽ¯ FunciÃ³n principal para generar keywords inteligentes"""
    generator = IntelligentKeywordGenerator()
    return generator.get_intelligent_keywords(query_text)

def get_multiple_search_variants(query_text: str, count: int = 3) -> List[str]:
    """ðŸ”„ Generar mÃºltiples variantes de bÃºsqueda para diversidad"""
    generator = IntelligentKeywordGenerator()
    return generator.get_multiple_search_variants(query_text, count)

def detect_granular_search_needs(query_text: str) -> List[Dict[str, str]]:
    """ðŸŽ¯ Detectar si una consulta necesita bÃºsquedas granulares mÃºltiples"""
    generator = IntelligentKeywordGenerator()
    return generator.detect_granular_search_needs(query_text)

# Testing directo si se ejecuta como script
if __name__ == "__main__":
    # Tests de casos problemÃ¡ticos reportados por el usuario
    test_cases = [
        "Buscar informaciÃ³n sobre 'Javier Milei' en bing y explorar los primeros resultados",
        "realizar anÃ¡lisis de datos especÃ­ficos sobre inteligencia artificial",  
        "genera informe sobre Arctic Monkeys discografÃ­a",
        "utilizar herramienta web_search para obtener datos econÃ³micos Argentina",
        "informaciÃ³n especÃ­fica sobre inflaciÃ³n Argentina 2024"
    ]
    
    print("ðŸ§ª TESTING INTELLIGENT KEYWORD GENERATOR")
    print("=" * 60)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nðŸ” TEST {i}: {test}")
        result = get_intelligent_keywords(test)
        print(f"âœ… RESULT: {result}")
        
        variants = get_multiple_search_variants(test, 2)
        print(f"ðŸ”„ VARIANTS: {variants}")
        print("-" * 40)

# Instancia global para usar en unified_web_search_tool.py
intelligent_keyword_generator = IntelligentKeywordGenerator()

def get_intelligent_keywords(query: str, num_variants: int = 1) -> str:
    """
    ðŸŽ¯ FUNCIÃ“N PRINCIPAL PARA REEMPLAZAR LAS FUNCIONES PROBLEMÃTICAS
    
    Args:
        query: Query original del usuario
        num_variants: NÃºmero de variantes (por defecto 1)
        
    Returns:
        str: Keywords inteligentes optimizados
    """
    if num_variants == 1:
        return intelligent_keyword_generator.get_intelligent_keywords(query)
    else:
        variants = intelligent_keyword_generator.get_multiple_search_variants(query, num_variants)
        return variants[0] if variants else "informaciÃ³n actualizada"

def get_multiple_search_variants(query: str, num_variants: int = 3) -> List[str]:
    """
    ðŸ“Š GENERAR MÃšLTIPLES VARIANTES PARA BÃšSQUEDAS DIVERSIFICADAS
    
    Args:
        query: Query original del usuario  
        num_variants: NÃºmero de variantes a generar
        
    Returns:
        List[str]: Lista de keywords variantes
    """
    return intelligent_keyword_generator.get_multiple_search_variants(query, num_variants)
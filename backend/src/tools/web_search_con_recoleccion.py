"""
üîç NAVEGACI√ìN WEB CON RECOLECCI√ìN EN TIEMPO REAL
===============================================

Herramienta mejorada que combina navegaci√≥n web with documentaci√≥n en vivo
de toda la informaci√≥n recolectada, mostrando en tiempo real en el terminal
del taskview lo que el agente va encontrando.

Funcionalidades:
- ‚úÖ Navegaci√≥n web inteligente
- ‚úÖ Documento .md que se actualiza en tiempo real
- ‚úÖ Eventos de terminal para cada informaci√≥n recolectada
- ‚úÖ Contenido completo de cada sitio visitado
"""

import asyncio
import time
import json
import logging
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
from urllib.parse import urljoin, urlparse

from .base_tool import BaseTool, ParameterDefinition, ToolExecutionResult, register_tool

try:
    from playwright.async_api import async_playwright
    PLAYWRIGHT_AVAILABLE = True
except ImportError:
    PLAYWRIGHT_AVAILABLE = False

# Importar sistema de documento en vivo
try:
    from ..services.documento_en_vivo import obtener_documento_en_vivo
    DOCUMENTO_EN_VIVO_AVAILABLE = True
except ImportError:
    DOCUMENTO_EN_VIVO_AVAILABLE = False

# Importar WebSocket manager
try:
    from ..websocket.websocket_manager import get_websocket_manager
    WEBSOCKET_AVAILABLE = True
except ImportError:
    WEBSOCKET_AVAILABLE = False

logger = logging.getLogger(__name__)

@register_tool
class WebSearchConRecoleccionEnVivo(BaseTool):
    """
    üîç B√öSQUEDA WEB CON RECOLECCI√ìN DOCUMENTADA EN TIEMPO REAL
    
    Esta herramienta navega la web y documenta en tiempo real TODA la informaci√≥n
    que va recolectando, mostrando en el terminal del taskview cada sitio visitado
    y el contenido extra√≠do.
    """
    
    def __init__(self):
        super().__init__(
            name="web_search_con_recoleccion",
            description="B√∫squeda web inteligente con documentaci√≥n en tiempo real de toda la informaci√≥n recolectada"
        )
        self.websocket_manager = None
        self.documento_en_vivo = None
        self.task_id = None
        self.max_sitios_config = 5
        
    def _define_parameters(self) -> List[ParameterDefinition]:
        return [
            ParameterDefinition(
                name="query",
                param_type="string",
                required=True,
                description="T√©rminos de b√∫squeda o consulta a investigar",
                min_value=3,
                max_value=200
            ),
            ParameterDefinition(
                name="max_sitios",
                param_type="integer",
                required=False,
                description="M√°ximo n√∫mero de sitios a explorar y documentar",
                default=5,
                min_value=1,
                max_value=10
            ),
            ParameterDefinition(
                name="profundidad_contenido",
                param_type="string",
                required=False,
                description="Nivel de detalle en extracci√≥n",
                default="completo",
                enum=["basico", "completo", "exhaustivo"]
            )
        ]
    
    def _execute_tool(self, parameters: Dict[str, Any], config: Dict[str, Any] = None) -> ToolExecutionResult:
        """üöÄ EJECUTAR B√öSQUEDA CON RECOLECCI√ìN DOCUMENTADA EN TIEMPO REAL"""
        
        if not PLAYWRIGHT_AVAILABLE:
            return ToolExecutionResult(
                success=False,
                error="Playwright no est√° disponible. Se requiere para navegaci√≥n web."
            )
        
        # Extraer par√°metros
        query = parameters.get('query', '').strip()
        max_sitios = int(parameters.get('max_sitios', 5))
        profundidad = parameters.get('profundidad_contenido', 'completo')
        
        # Obtener task_id del config
        self.task_id = config.get('task_id') if config else f"search-{int(time.time())}"
        self.max_sitios_config = max_sitios
        
        # Inicializar sistemas
        self._inicializar_sistemas()
        
        try:
            # Ejecutar b√∫squeda con recolecci√≥n documentada
            resultados = self._ejecutar_busqueda_con_documentacion(query, max_sitios, profundidad)
            
            # Finalizar documento
            if self.documento_en_vivo:
                resumen = self._generar_resumen_final(resultados)
                self.documento_en_vivo.finalizar_documento(resumen)
            
            return ToolExecutionResult(
                success=True,
                data={
                    'query': query,
                    'sitios_explorados': len(resultados.get('sitios_visitados', [])),
                    'contenido_total_caracteres': resultados.get('contenido_total_caracteres', 0),
                    'documento_path': self.documento_en_vivo.documento_path if self.documento_en_vivo else None,
                    'resultados_detallados': resultados,
                    'timestamp': datetime.now().isoformat()
                }
            )
            
        except Exception as e:
            logger.error(f"‚ùå Error en b√∫squeda web con recolecci√≥n: {e}")
            return ToolExecutionResult(
                success=False,
                error=f"Error en b√∫squeda web: {str(e)}"
            )
    
    def _inicializar_sistemas(self):
        """üîÑ Inicializar WebSocket y documento en vivo."""
        try:
            # Inicializar WebSocket manager
            if WEBSOCKET_AVAILABLE:
                self.websocket_manager = get_websocket_manager()
                if self.websocket_manager:
                    logger.info("‚úÖ WebSocket manager inicializado para recolecci√≥n en vivo")
            
            # Inicializar documento en vivo
            if DOCUMENTO_EN_VIVO_AVAILABLE and self.task_id:
                self.documento_en_vivo = obtener_documento_en_vivo(self.task_id, self.websocket_manager)
                if self.documento_en_vivo:
                    logger.info(f"‚úÖ Documento en vivo inicializado: {self.documento_en_vivo.documento_path}")
            
        except Exception as e:
            logger.error(f"‚ùå Error inicializando sistemas: {e}")
    
    def _ejecutar_busqueda_con_documentacion(self, query: str, max_sitios: int, profundidad: str) -> Dict[str, Any]:
        """üåê EJECUTAR B√öSQUEDA COMPLETA CON DOCUMENTACI√ìN EN TIEMPO REAL"""
        
        # Actualizar estado inicial
        if self.documento_en_vivo:
            self.documento_en_vivo.actualizar_estado_navegacion(
                "Iniciando b√∫squeda web",
                f"B√∫squeda: '{query}' | Sitios objetivo: {max_sitios} | Profundidad: {profundidad}"
            )
        
        # Crear nuevo event loop para evitar conflictos
        loop = asyncio.new_event_loop()
        asyncio.set_event_loop(loop)
        
        try:
            return loop.run_until_complete(
                self._busqueda_asincrona_con_documentacion(query, max_sitios, profundidad)
            )
        finally:
            loop.close()
    
    async def _busqueda_asincrona_con_documentacion(self, query: str, max_sitios: int, profundidad: str) -> Dict[str, Any]:
        """üé≠ B√öSQUEDA AS√çNCRONA CON PLAYWRIGHT Y DOCUMENTACI√ìN COMPLETA"""
        
        resultados = {
            'query': query,
            'sitios_visitados': [],
            'contenido_total_caracteres': 0,
            'timestamp_inicio': datetime.now().isoformat(),
            'timestamp_fin': None
        }
        
        async with async_playwright() as p:
            # Configurar navegador
            browser = await p.chromium.launch(
                headless=False,  # Navegaci√≥n visible
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    f'--display={os.environ.get("DISPLAY", ":99")}',
                    '--window-size=1920,1080'
                ]
            )
            
            context = await browser.new_context(
                viewport={'width': 1920, 'height': 1080}
            )
            
            page = await context.new_page()
            
            try:
                # Actualizar estado: navegando a Google
                if self.documento_en_vivo:
                    self.documento_en_vivo.actualizar_estado_navegacion(
                        "Navegando a Google",
                        "Preparando b√∫squeda inicial"
                    )
                
                # 1. Navegar a Google
                await page.goto('https://www.google.com', wait_until='networkidle')
                await asyncio.sleep(1)
                
                # 2. Realizar b√∫squeda
                await self._realizar_busqueda_google(page, query)
                
                # 3. Obtener enlaces de resultados
                enlaces_resultados = await self._obtener_enlaces_resultados(page)
                
                # 4. Explorar cada sitio y documentar contenido
                sitios_explorados = 0
                for i, enlace in enumerate(enlaces_resultados[:max_sitios]):
                    try:
                        if sitios_explorados >= max_sitios:
                            break
                        
                        sitio_info = await self._explorar_sitio_con_documentacion(
                            page, enlace, i + 1, profundidad
                        )
                        
                        if sitio_info:
                            resultados['sitios_visitados'].append(sitio_info)
                            resultados['contenido_total_caracteres'] += len(sitio_info.get('contenido', ''))
                            sitios_explorados += 1
                            
                            # Peque√±a pausa entre sitios
                            await asyncio.sleep(2)
                        
                    except Exception as e:
                        logger.error(f"‚ùå Error explorando sitio {i+1}: {e}")
                        continue
                
                # Actualizar estado final
                if self.documento_en_vivo:
                    self.documento_en_vivo.actualizar_estado_navegacion(
                        "B√∫squeda completada",
                        f"Se exploraron {sitios_explorados} sitios exitosamente"
                    )
                
                resultados['timestamp_fin'] = datetime.now().isoformat()
                return resultados
                
            finally:
                await context.close()
                await browser.close()
    
    async def _realizar_busqueda_google(self, page, query: str):
        """üîç Realizar b√∫squeda en Google con documentaci√≥n."""
        
        try:
            # Buscar campo de b√∫squeda
            search_input = await page.wait_for_selector('textarea[name="q"], input[name="q"]', timeout=5000)
            
            if self.documento_en_vivo:
                self.documento_en_vivo.actualizar_estado_navegacion(
                    "Escribiendo b√∫squeda",
                    f"Introduciendo t√©rminos: '{query}'"
                )
            
            # Escribir b√∫squeda
            await search_input.fill(query)
            await asyncio.sleep(1)
            await search_input.press('Enter')
            
            # Esperar resultados
            await page.wait_for_load_state('networkidle')
            await asyncio.sleep(2)
            
            logger.info(f"üîç B√∫squeda realizada para: {query}")
            
        except Exception as e:
            logger.error(f"‚ùå Error realizando b√∫squeda: {e}")
            raise
    
    async def _obtener_enlaces_resultados(self, page) -> List[Dict[str, str]]:
        """üîó Obtener enlaces de resultados de b√∫squeda."""
        
        enlaces = []
        
        try:
            # Selectores para diferentes motores de b√∫squeda
            selectores_enlaces = [
                'h3 a',  # Google est√°ndar
                '.g h3 a',  # Google espec√≠fico
                '.b_algo h2 a',  # Bing
                '.result h3 a',  # Gen√©rico
                'a[href*="http"]:has(h3)',  # Fallback
            ]
            
            for selector in selectores_enlaces:
                try:
                    elementos = await page.query_selector_all(selector)
                    if elementos:
                        for elemento in elementos[:15]:  # M√°ximo 15 enlaces
                            try:
                                href = await elemento.get_attribute('href')
                                texto = await elemento.text_content()
                                
                                if href and texto and 'google.com' not in href:
                                    enlaces.append({
                                        'url': href,
                                        'titulo': texto.strip(),
                                        'fuente': urlparse(href).netloc
                                    })
                            except:
                                continue
                        break  # Si encontramos enlaces con este selector, usar estos
                except:
                    continue
            
            if self.documento_en_vivo:
                self.documento_en_vivo.actualizar_estado_navegacion(
                    "Enlaces encontrados",
                    f"Se encontraron {len(enlaces)} enlaces para explorar"
                )
            
            logger.info(f"üîó Se encontraron {len(enlaces)} enlaces de resultados")
            return enlaces
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo enlaces: {e}")
            return []
    
    async def _explorar_sitio_con_documentacion(self, page, enlace: Dict[str, str], 
                                               numero_sitio: int, profundidad: str) -> Optional[Dict[str, Any]]:
        """
        üåê EXPLORAR SITIO INDIVIDUAL CON DOCUMENTACI√ìN COMPLETA EN TIEMPO REAL
        
        Args:
            page: P√°gina de Playwright
            enlace: Informaci√≥n del enlace (url, titulo, fuente)
            numero_sitio: N√∫mero del sitio en la secuencia
            profundidad: Nivel de extracci√≥n de contenido
            
        Returns:
            Informaci√≥n completa del sitio explorado
        """
        
        url = enlace['url']
        titulo_enlace = enlace['titulo']
        fuente = enlace['fuente']
        
        try:
            # Actualizar estado: navegando a sitio espec√≠fico
            if self.documento_en_vivo:
                self.documento_en_vivo.actualizar_estado_navegacion(
                    f"Navegando a sitio {numero_sitio}/{self.max_sitios_config}",
                    f"üåê Accediendo a: {fuente}"
                )
            
            logger.info(f"üåê Navegando a sitio {numero_sitio}: {url}")
            
            # Navegar al sitio
            await page.goto(url, wait_until='networkidle', timeout=15000)
            await asyncio.sleep(2)
            
            # Obtener informaci√≥n b√°sica del sitio
            titulo_pagina = await page.title()
            url_final = page.url  # Por si hubo redirects
            
            # Actualizar estado: extrayendo contenido
            if self.documento_en_vivo:
                self.documento_en_vivo.actualizar_estado_navegacion(
                    f"Extrayendo contenido de sitio {numero_sitio}",
                    f"üìÑ Procesando: {titulo_pagina[:50]}..."
                )
            
            # Extraer contenido seg√∫n profundidad
            contenido_extraido = await self._extraer_contenido_completo(page, profundidad)
            
            # Obtener metadatos adicionales
            metadatos = await self._obtener_metadatos_sitio(page)
            
            # Crear informaci√≥n completa del sitio
            sitio_info = {
                'numero': numero_sitio,
                'url': url_final,
                'url_original': url,
                'titulo': titulo_pagina,
                'titulo_enlace': titulo_enlace,
                'fuente': fuente,
                'contenido': contenido_extraido,
                'caracteres': len(contenido_extraido),
                'timestamp': datetime.now().isoformat(),
                'metadatos': metadatos
            }
            
            # üî• PUNTO CLAVE: AGREGAR AL DOCUMENTO EN VIVO INMEDIATAMENTE
            if self.documento_en_vivo:
                self.documento_en_vivo.agregar_sitio_visitado(
                    url=url_final,
                    titulo=titulo_pagina,
                    contenido=contenido_extraido,
                    metadatos={
                        'numero_sitio': numero_sitio,
                        'fuente_dominio': fuente,
                        'url_original': url,
                        'titulo_enlace': titulo_enlace,
                        'metodo_extraccion': metadatos.get('metodo_extraccion', 'unknown'),
                        'tiempo_carga': metadatos.get('tiempo_carga', 0),
                        'profundidad': profundidad
                    }
                )
            
            logger.info(f"‚úÖ Sitio {numero_sitio} documentado: {titulo_pagina} ({len(contenido_extraido)} chars)")
            
            return sitio_info
            
        except Exception as e:
            logger.error(f"‚ùå Error explorando sitio {numero_sitio} ({url}): {e}")
            
            # Documentar error tambi√©n
            if self.documento_en_vivo:
                self.documento_en_vivo.agregar_sitio_visitado(
                    url=url,
                    titulo=f"ERROR: {titulo_enlace}",
                    contenido=f"No se pudo acceder al sitio debido a: {str(e)}",
                    metadatos={
                        'numero_sitio': numero_sitio,
                        'error': True,
                        'error_message': str(e),
                        'url_original': url
                    }
                )
            
            return None
    
    async def _extraer_contenido_completo(self, page, profundidad: str) -> str:
        """
        üìÑ EXTRAER CONTENIDO COMPLETO DE LA P√ÅGINA
        
        Args:
            page: P√°gina de Playwright
            profundidad: Nivel de detalle ('basico', 'completo', 'exhaustivo')
            
        Returns:
            Contenido completo extra√≠do de la p√°gina
        """
        
        try:
            # Script de extracci√≥n inteligente seg√∫n profundidad
            if profundidad == "exhaustivo":
                max_chars = 8000
                selectors_extra = ['.abstract', '.intro', '.summary', '.conclusion']
            elif profundidad == "completo":
                max_chars = 5000
                selectors_extra = ['.summary', '.intro']
            else:  # basico
                max_chars = 2000
                selectors_extra = []
            
            contenido = await page.evaluate(f'''
                () => {{
                    let contenido = '';
                    let seccionesExtraidas = [];
                    
                    // 1. BUSCAR CONTENIDO PRINCIPAL DE ART√çCULO
                    const selectoresPrincipales = [
                        'article', 'main', '[role="main"]', '.article', '.post',
                        '.content', '.entry-content', '.post-content', '.article-content',
                        '#content', '#main', '.main-content', '.page-content'
                    ];
                    
                    for (let selector of selectoresPrincipales) {{
                        const elemento = document.querySelector(selector);
                        if (elemento && elemento.innerText && elemento.innerText.length > 300) {{
                            contenido = elemento.innerText || elemento.textContent || '';
                            seccionesExtraidas.push(selector);
                            break;
                        }}
                    }}
                    
                    // 2. AGREGAR SECCIONES ESPEC√çFICAS SEG√öN PROFUNDIDAD
                    const selectoresExtra = {json.dumps(selectors_extra)};
                    for (let selector of selectoresExtra) {{
                        const elemento = document.querySelector(selector);
                        if (elemento && elemento.innerText) {{
                            contenido += '\\n\\n=== ' + selector.toUpperCase() + ' ===\\n';
                            contenido += elemento.innerText;
                            seccionesExtraidas.push(selector);
                        }}
                    }}
                    
                    // 3. SI NO HAY CONTENIDO SUFICIENTE, EXTRAER P√ÅRRAFOS
                    if (!contenido || contenido.length < 500) {{
                        const parrafos = document.querySelectorAll('p, .paragraph, .text');
                        let contenidoParrafos = '';
                        for (let p of parrafos) {{
                            if (p.innerText && p.innerText.length > 50) {{
                                contenidoParrafos += p.innerText + '\\n\\n';
                                if (contenidoParrafos.length > 3000) break;
                            }}
                        }}
                        if (contenidoParrafos.length > contenido.length) {{
                            contenido = contenidoParrafos;
                            seccionesExtraidas.push('paragraphs');
                        }}
                    }}
                    
                    // 4. √öLTIMO RECURSO: BODY COMPLETO FILTRADO
                    if (!contenido || contenido.length < 300) {{
                        contenido = document.body.innerText || document.body.textContent || '';
                        seccionesExtraidas.push('body-fallback');
                    }}
                    
                    // 5. LIMPIAR CONTENIDO
                    contenido = contenido.replace(/\\s+/g, ' ').trim();
                    
                    // Remover texto de navegaci√≥n com√∫n
                    const textoNavegacion = [
                        'Skip to content', 'Menu', 'Navigation', 'Home', 'About', 'Contact',
                        'Privacy Policy', 'Terms', 'Cookie', 'Subscribe', 'Newsletter',
                        'Aceptar cookies', 'Pol√≠tica de privacidad', 'Men√∫', 'Inicio'
                    ];
                    
                    for (let navText of textoNavegacion) {{
                        contenido = contenido.replace(new RegExp(navText, 'gi'), '');
                    }}
                    
                    // 6. LIMITAR SEG√öN PROFUNDIDAD
                    const maxChars = {max_chars};
                    if (contenido.length > maxChars) {{
                        contenido = contenido.substring(0, maxChars) + '\\n\\n[CONTENIDO TRUNCADO - L√çMITE DE CARACTERES ALCANZADO]';
                    }}
                    
                    return {{
                        contenido: contenido,
                        longitud: contenido.length,
                        metodosExtraccion: seccionesExtraidas.join(', '),
                        calidad: contenido.length > 2000 ? 'alta' : contenido.length > 1000 ? 'media' : 'baja'
                    }};
                }}
            ''')
            
            # Extraer datos del resultado
            if isinstance(contenido, dict):
                texto_contenido = contenido.get('contenido', '')
            else:
                texto_contenido = contenido or ''
            
            logger.info(f"üìÑ Contenido extra√≠do: {len(texto_contenido)} caracteres")
            return texto_contenido
            
        except Exception as e:
            logger.error(f"‚ùå Error extrayendo contenido: {e}")
            return f"Error extrayendo contenido: {str(e)}"
    
    async def _obtener_metadatos_sitio(self, page) -> Dict[str, Any]:
        """üìã Obtener metadatos adicionales del sitio."""
        
        try:
            # Obtener metadatos b√°sicos
            metadatos = await page.evaluate('''
                () => {
                    const meta = {};
                    
                    // Meta tags
                    const metaTags = document.querySelectorAll('meta');
                    for (let tag of metaTags) {
                        const name = tag.getAttribute('name') || tag.getAttribute('property');
                        const content = tag.getAttribute('content');
                        if (name && content) {
                            meta[name] = content;
                        }
                    }
                    
                    // Informaci√≥n adicional
                    return {
                        titulo: document.title,
                        descripcion: meta['description'] || meta['og:description'] || '',
                        autor: meta['author'] || meta['article:author'] || '',
                        fecha_publicacion: meta['article:published_time'] || meta['date'] || '',
                        idioma: document.documentElement.lang || 'unknown',
                        tipo_contenido: meta['og:type'] || 'website',
                        imagen_destacada: meta['og:image'] || '',
                        palabras_clave: meta['keywords'] || '',
                        url_canonica: document.querySelector('link[rel="canonical"]')?.href || window.location.href
                    };
                }
            ''')
            
            # Agregar timestamp y informaci√≥n t√©cnica
            metadatos.update({
                'timestamp_extraccion': datetime.now().isoformat(),
                'tiempo_carga': time.time()
            })
            
            return metadatos
            
        except Exception as e:
            logger.error(f"‚ùå Error obteniendo metadatos: {e}")
            return {
                'error': str(e),
                'timestamp_extraccion': datetime.now().isoformat()
            }
    
    def _generar_resumen_final(self, resultados: Dict[str, Any]) -> str:
        """üìä Generar resumen final de la recolecci√≥n."""
        
        sitios_exitosos = len(resultados.get('sitios_visitados', []))
        total_caracteres = resultados.get('contenido_total_caracteres', 0)
        
        if sitios_exitosos == 0:
            return "‚ùå No se pudo recolectar informaci√≥n de ning√∫n sitio web."
        
        promedio_caracteres = total_caracteres // sitios_exitosos if sitios_exitosos > 0 else 0
        
        # Obtener estad√≠sticas de fuentes
        fuentes_unicas = set()
        for sitio in resultados.get('sitios_visitados', []):
            if sitio.get('fuente'):
                fuentes_unicas.add(sitio['fuente'])
        
        resumen = f"""
## üìä ESTAD√çSTICAS FINALES DE RECOLECCI√ìN

### Resultados Generales
- ‚úÖ **Sitios explorados exitosamente**: {sitios_exitosos}
- üåê **Fuentes √∫nicas consultadas**: {len(fuentes_unicas)}
- üìÑ **Total caracteres recolectados**: {total_caracteres:,}
- üìä **Promedio por sitio**: {promedio_caracteres:,} caracteres

### Fuentes Consultadas
"""
        
        for fuente in sorted(fuentes_unicas):
            resumen += f"- üîó {fuente}\n"
        
        resumen += f"""
### Calidad de la Recolecci√≥n
- ‚≠ê **Calidad general**: {'Excelente' if total_caracteres > 15000 else 'Buena' if total_caracteres > 8000 else 'B√°sica'}
- üéØ **Diversidad de fuentes**: {'Alta' if len(fuentes_unicas) >= 4 else 'Media' if len(fuentes_unicas) >= 2 else 'Baja'}
- üìà **Completitud**: {'Completa' if sitios_exitosos >= 4 else 'Parcial'}

### Tiempo de Ejecuci√≥n
- üïê **Inicio**: {resultados.get('timestamp_inicio', 'N/A')}
- üèÅ **Fin**: {resultados.get('timestamp_fin', datetime.now().isoformat())}

**üéØ CONCLUSI√ìN**: La recolecci√≥n de informaci√≥n se complet√≥ {'exitosamente' if sitios_exitosos >= 3 else 'parcialmente'} con datos sustanciales de m√∫ltiples fuentes web."""
        
        return resumen
    
    def _emit_progress(self, message: str):
        """Emitir mensaje de progreso."""
        logger.info(message)
        if self.websocket_manager and self.task_id:
            try:
                self.websocket_manager.send_log_message(
                    task_id=self.task_id,
                    level="info",
                    message=message
                )
            except Exception as e:
                logger.error(f"‚ùå Error enviando progreso WebSocket: {e}")

# Funci√≥n auxiliar para configurar la herramienta
def configurar_herramienta_con_documento(task_id: str, max_sitios: int = 5):
    """Configura la herramienta con par√°metros espec√≠ficos."""
    herramienta = WebSearchConRecoleccionEnVivo()
    herramienta.task_id = task_id
    herramienta.max_sitios_config = max_sitios
    return herramienta
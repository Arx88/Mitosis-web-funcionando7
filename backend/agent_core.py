"""
N√∫cleo del Agente Mitosis Mejorado
Integra todos los componentes: modelos, memoria, tareas y prompts
"""

import logging
import json
import time
import os
from typing import List, Dict, Optional, Any, Union
from dataclasses import dataclass
import asyncio
from enum import Enum
import jsonschema
import re

from model_manager import ModelManager, UnifiedModel, ModelProvider
from memory_manager import MemoryManager, Message, TaskMemory, KnowledgeItem
from task_manager import TaskManager, Task, TaskPhase, TaskStatus
from enhanced_prompts import EnhancedPromptManager, PromptType
from intention_classifier import IntentionClassifier, IntentionType
from web_browser_manager import WebBrowserManager, BrowserConfig, ScrapingMode, search_web_simple

class AgentState(Enum):
    """Estados del agente"""
    IDLE = "idle"
    THINKING = "thinking"
    PLANNING = "planning"
    EXECUTING = "executing"
    REFLECTING = "reflecting"
    WAITING_USER = "waiting_user"
    ERROR = "error"

# Esquema JSON para validaci√≥n de planes generados seg√∫n UPGRADE.md
PLAN_SCHEMA = {
    "type": "object",
    "required": ["goal", "phases"],
    "properties": {
        "goal": {
            "type": "string",
            "minLength": 3
        },
        "phases": {
            "type": "array",
            "minItems": 1,
            "maxItems": 10,
            "items": {
                "type": "object",
                "required": ["id", "title", "description", "required_capabilities"],
                "properties": {
                    "id": {
                        "type": "integer",
                        "minimum": 1
                    },
                    "title": {
                        "type": "string",
                        "minLength": 5,
                        "maxLength": 100
                    },
                    "description": {
                        "type": "string", 
                        "minLength": 10,
                        "maxLength": 300
                    },
                    "required_capabilities": {
                        "type": "array",
                        "items": {
                            "type": "string",
                            "enum": ["analysis", "web_search", "creation", "planning", "delivery", "processing", "synthesis", "general", "communication"]
                        }
                    },
                    "estimated_time": {
                        "type": "string"
                    },
                    "tool_name": {
                        "type": "string",
                        "enum": ["web_search", "file_write", "analysis", "creation", "shell_exec", "general"]
                    }
                },
                "additionalProperties": False
            }
        }
    },
    "additionalProperties": False
}

@dataclass
class AgentConfig:
    """Configuraci√≥n del agente"""
    # Configuraci√≥n de modelos
    ollama_url: str = "http://localhost:11434"
    openrouter_api_key: Optional[str] = None
    prefer_local_models: bool = True
    max_cost_per_1k_tokens: float = 0.01
    
    # Configuraci√≥n de memoria
    memory_db_path: str = "mitosis_memory.db"
    max_short_term_messages: int = 50
    
    # Configuraci√≥n de tareas
    max_concurrent_tasks: int = 1
    auto_retry_failed_phases: bool = True
    
    # Configuraci√≥n de prompts
    max_context_tokens: int = 4000
    include_memory_context: bool = True
    
    # Configuraci√≥n general
    agent_name: str = "Mitosis"
    debug_mode: bool = False
    log_level: str = "INFO"

class MitosisAgent:
    """Agente Mitosis mejorado con integraci√≥n completa"""
    
    def __init__(self, config: Optional[AgentConfig] = None):
        self.config = config or AgentConfig()
        
        # Configurar logging
        logging.basicConfig(
            level=getattr(logging, self.config.log_level),
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
        
        # Estado del agente
        self.state = AgentState.IDLE
        self.current_session_id = None
        self.startup_time = time.time()
        
        # Inicializar componentes
        self._initialize_components()
        
        # Estad√≠sticas
        self.stats = {
            "tasks_completed": 0,
            "tasks_failed": 0,
            "messages_processed": 0,
            "models_used": set(),
            "uptime": 0
        }
        
        self.logger.info(f"Agente {self.config.agent_name} inicializado correctamente")
    
    def _initialize_components(self):
        """Inicializa todos los componentes del agente"""
        try:
            # Inicializar gestor de memoria
            self.memory_manager = MemoryManager(
                db_path=self.config.memory_db_path,
                max_short_term_messages=self.config.max_short_term_messages
            )
            
            # Inicializar gestor de tareas
            self.task_manager = TaskManager(self.memory_manager)
            self.task_manager.max_concurrent_tasks = self.config.max_concurrent_tasks
            self.task_manager.auto_retry_failed_phases = self.config.auto_retry_failed_phases
            
            # Inicializar gestor de modelos
            self.model_manager = ModelManager(
                ollama_url=self.config.ollama_url,
                openrouter_api_key=self.config.openrouter_api_key
            )
            self.model_manager.prefer_local = self.config.prefer_local_models
            
            # Inicializar gestor de prompts
            self.prompt_manager = EnhancedPromptManager(
                self.memory_manager, 
                self.task_manager
            )
            self.prompt_manager.max_context_tokens = self.config.max_context_tokens
            self.prompt_manager.include_memory_context = self.config.include_memory_context
            
            # Inicializar clasificador de intenciones (NUEVA MEJORA)
            self.intention_classifier = IntentionClassifier(
                self.model_manager,
                self.memory_manager
            )
            
            # Inicializar gestor de navegaci√≥n web (NUEVA MEJORA - FASE 2)
            self.web_browser_manager = WebBrowserManager(BrowserConfig(headless=True))
            
            # Actualizar modelos disponibles
            self.model_manager.refresh_models()
            
            self.logger.info("Todos los componentes inicializados correctamente")
            self.logger.info("üéØ IntentionClassifier inicializado - Detecci√≥n LLM habilitada")
            self.logger.info("üåê WebBrowserManager inicializado - Navegaci√≥n real habilitada")
            
        except Exception as e:
            self.logger.error(f"Error al inicializar componentes: {e}")
            raise
    
    def start_session(self, session_id: Optional[str] = None) -> str:
        """Inicia una nueva sesi√≥n de conversaci√≥n"""
        if session_id:
            self.current_session_id = session_id
        else:
            self.current_session_id = f"session_{int(time.time())}"
        
        # Limpiar memoria a corto plazo para nueva sesi√≥n
        self.memory_manager.clear_short_term_memory(persist=True)
        
        # A√±adir mensaje de inicio de sesi√≥n
        self.memory_manager.add_message(
            "system", 
            f"Sesi√≥n iniciada: {self.current_session_id}",
            {"session_start": True, "timestamp": time.time()}
        )
        
        self.logger.info(f"Nueva sesi√≥n iniciada: {self.current_session_id}")
        return self.current_session_id
    
    def process_user_input(self, message: str, context: Optional[Dict[str, Any]] = None) -> str:
        """
        Procesa la entrada del usuario con clasificaci√≥n de intenci√≥n inteligente
        NUEVA MEJORA: Reemplaza l√≥gica heur√≠stica con LLM dedicado
        """
        try:
            self.state = AgentState.THINKING
            self.stats["messages_processed"] += 1
            
            # A√±adir mensaje del usuario a la memoria
            self.memory_manager.add_message("user", message, context or {})
            
            # CLASIFICAR INTENCI√ìN usando LLM dedicado
            conversation_context = self.memory_manager.get_conversation_context(max_tokens=1000)
            active_tasks = [
                {
                    'title': task.title, 
                    'status': task.status.value,
                    'id': task.id
                } 
                for task in self.task_manager.list_tasks(TaskStatus.ACTIVE)[:5]
            ]
            
            intention_result = self.intention_classifier.classify_intention(
                user_message=message,
                conversation_context=conversation_context,
                active_tasks=active_tasks
            )
            
            self.logger.info(f"üéØ Intenci√≥n clasificada: {intention_result.intention_type.value} "
                           f"(confianza: {intention_result.confidence:.2f})")
            
            # Registrar clasificaci√≥n en memoria para an√°lisis futuro
            self.memory_manager.add_knowledge(
                content=f"Intenci√≥n clasificada: {intention_result.intention_type.value} - {intention_result.reasoning}",
                category="intention_classification",
                source="intention_classifier",
                confidence=intention_result.confidence,
                tags=["intention", "classification", "llm"]
            )
            
            # ENRUTAR seg√∫n intenci√≥n clasificada
            if intention_result.requires_clarification:
                return self._handle_clarification_request(intention_result)
            
            elif intention_result.intention_type == IntentionType.CASUAL_CONVERSATION:
                return self.process_user_message(message, context)
            
            elif intention_result.intention_type == IntentionType.INFORMATION_REQUEST:
                return self._handle_information_request(message, intention_result, context)
            
            elif intention_result.intention_type in [IntentionType.SIMPLE_TASK, IntentionType.COMPLEX_TASK]:
                return self._handle_task_creation(message, intention_result, context)
            
            elif intention_result.intention_type == IntentionType.TASK_MANAGEMENT:
                return self._handle_task_management(message, intention_result, context)
            
            elif intention_result.intention_type == IntentionType.AGENT_CONFIGURATION:
                return self._handle_agent_configuration(message, intention_result, context)
            
            else:  # UNCLEAR
                return self._handle_unclear_intention(message, intention_result, context)
    
        except Exception as e:
            self.logger.error(f"Error en procesamiento de entrada con clasificaci√≥n: {e}")
            # Fallback al m√©todo original
            return self.process_user_message(message, context)
    
    def _handle_clarification_request(self, intention_result) -> str:
        """Maneja solicitudes que requieren clarificaci√≥n"""
        clarification_message = "Necesito m√°s informaci√≥n para ayudarte mejor. "
        if intention_result.clarification_questions:
            clarification_message += "Espec√≠ficamente:\n"
            for i, question in enumerate(intention_result.clarification_questions, 1):
                clarification_message += f"{i}. {question}\n"
        else:
            clarification_message += "¬øPodr√≠as ser m√°s espec√≠fico sobre lo que necesitas?"
        
        return clarification_message

    def _handle_information_request(self, message: str, intention_result, 
                                   context: Optional[Dict[str, Any]]) -> str:
        """Maneja solicitudes de informaci√≥n con b√∫squeda en memoria"""
        # Buscar en memoria primero
        search_terms = intention_result.extracted_entities.get('search_terms', message)
        knowledge_results = self.memory_manager.search_knowledge(search_terms, limit=5)
        
        if knowledge_results:
            # Usar conocimiento existente
            knowledge_context = "\n".join([item.content for item in knowledge_results[:3]])
            enhanced_message = f"Bas√°ndome en mi conocimiento previo:\n{knowledge_context}\n\nPregunta: {message}"
            return self.process_user_message(enhanced_message, context)
        else:
            # Si no hay conocimiento previo, procesar normalmente
            # En el futuro, aqu√≠ se activar√≠a la b√∫squeda web real
            return self.process_user_message(message, context)

    def _handle_task_creation(self, message: str, intention_result, 
                             context: Optional[Dict[str, Any]]) -> str:
        """Maneja la creaci√≥n de tareas simples y complejas con entidades extra√≠das"""
        entities = intention_result.extracted_entities
        
        title = entities.get('task_title', message[:100])
        description = entities.get('task_description', message)
        goal = f"Completar la solicitud del usuario: {message}"
        
        # Determinar si es tarea compleja bas√°ndose en la clasificaci√≥n y entidades
        is_complex = (intention_result.intention_type == IntentionType.COMPLEX_TASK or 
                      len(entities.get('mentioned_tools', [])) > 1 or
                      'time_constraints' in entities)
        
        if is_complex:
            self.logger.info(f"üèóÔ∏è Creando tarea compleja: {title}")
            return self.create_and_execute_task(title, description, goal, auto_execute=True)
        else:
            # Para tareas simples, crear un plan m√°s directo
            self.logger.info(f"‚ö° Creando tarea simple: {title}")
            simple_phases = [
                {
                    "id": 1,
                    "title": f"Ejecutar: {title}",
                    "description": description,
                    "required_capabilities": ["general"]
                }
            ]
            task_id = self.task_manager.create_task(title, description, goal, simple_phases)
            if self.task_manager.start_task(task_id):
                return f"Tarea simple '{title}' creada e iniciada."
            else:
                return f"Tarea simple '{title}' creada pero no se pudo iniciar."

    def _handle_task_management(self, message: str, intention_result, 
                               context: Optional[Dict[str, Any]]) -> str:
        """Maneja comandos de gesti√≥n de tareas"""
        entities = intention_result.extracted_entities
        task_reference = entities.get('task_reference', '')
        
        # Obtener tareas activas
        active_tasks = self.task_manager.list_tasks(TaskStatus.ACTIVE)
        
        if not active_tasks:
            return "No tienes tareas activas en este momento."
        
        if 'estado' in message.lower() or 'progreso' in message.lower():
            # Mostrar estado de tareas
            status_message = "üìã Estado de tus tareas activas:\n\n"
            for task in active_tasks:
                current_phase = self.task_manager.get_current_phase(task.id)
                phase_info = f" - Fase actual: {current_phase.title}" if current_phase else ""
                status_message += f"‚Ä¢ **{task.title}** ({task.status.value}){phase_info}\n"
            
            return status_message
        
        elif 'pausar' in message.lower():
            # Pausar tareas activas
            paused_count = 0
            for task in active_tasks:
                if self.task_manager.pause_task(task.id):
                    paused_count += 1
            return f"Se pausaron {paused_count} tareas."
        
        elif 'reanudar' in message.lower():
            # Reanudar tareas pausadas
            paused_tasks = self.task_manager.list_tasks(TaskStatus.PAUSED)
            resumed_count = 0
            for task in paused_tasks:
                if self.task_manager.resume_task(task.id):
                    resumed_count += 1
            return f"Se reanudaron {resumed_count} tareas."
        
        else:
            return "No entiendo qu√© operaci√≥n quieres realizar con las tareas. ¬øEstado, pausar o reanudar?"

    def _handle_agent_configuration(self, message: str, intention_result, 
                                   context: Optional[Dict[str, Any]]) -> str:
        """Maneja solicitudes de configuraci√≥n del agente"""
        return ("Las funciones de configuraci√≥n del agente est√°n en desarrollo. "
                "Por ahora, puedes consultar mi estado actual o crear nuevas tareas.")

    def _handle_unclear_intention(self, message: str, intention_result, 
                                 context: Optional[Dict[str, Any]]) -> str:
        """Maneja mensajes con intenci√≥n poco clara"""
        clarification = ("No estoy seguro de qu√© quieres que haga. ¬øPodr√≠as ser m√°s espec√≠fico? "
                        "Puedo ayudarte con:\n"
                        "‚Ä¢ Responder preguntas\n"
                        "‚Ä¢ Crear y ejecutar tareas\n"
                        "‚Ä¢ Consultar el estado de tareas\n"
                        "‚Ä¢ Conversaci√≥n general")
        
        # Tambi√©n procesar como conversaci√≥n por si acaso
        conversation_response = self.process_user_message(message, context)
        
        return f"{clarification}\n\nMientras tanto, aqu√≠ tienes mi respuesta: {conversation_response}"
    
    def process_user_message(self, message: str, context: Optional[Dict[str, Any]] = None) -> str:
        """Procesa un mensaje del usuario y genera una respuesta"""
        try:
            self.state = AgentState.THINKING
            self.stats["messages_processed"] += 1
            
            # A√±adir mensaje del usuario a la memoria
            self.memory_manager.add_message("user", message, context or {})
            
            # Generar prompt del sistema con contexto
            system_prompt = self.prompt_manager.generate_system_prompt(
                context=f"Mensaje del usuario: {message}"
            )
            
            # Seleccionar mejor modelo para la respuesta
            best_model = self.model_manager.select_best_model(
                task_type="chat",
                max_cost=self.config.max_cost_per_1k_tokens
            )
            
            if not best_model:
                return "Error: No hay modelos disponibles para procesar la solicitud."
            
            # Cargar modelo si es necesario
            if not self.model_manager.load_model(best_model):
                return "Error: No se pudo cargar el modelo seleccionado."
            
            # Preparar mensajes para el modelo
            conversation_context = self.memory_manager.get_conversation_context(
                max_tokens=self.config.max_context_tokens // 2
            )
            
            messages = [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Contexto de conversaci√≥n:\n{conversation_context}\n\nMensaje actual: {message}"}
            ]
            
            # Generar respuesta
            self.stats["models_used"].add(best_model.name)
            response = self.model_manager.chat_completion(
                messages=messages,
                model=best_model,
                max_tokens=1000,
                temperature=0.7
            )
            
            if not response:
                return "Error: No se pudo generar una respuesta."
            
            # A√±adir respuesta a la memoria
            self.memory_manager.add_message(
                "assistant", 
                response,
                {"model_used": best_model.name, "provider": best_model.provider.value}
            )
            
            # Extraer conocimiento si es relevante
            self._extract_knowledge_from_conversation(message, response)
            
            self.state = AgentState.IDLE
            return response
            
        except Exception as e:
            self.logger.error(f"Error al procesar mensaje del usuario: {e}")
            self.state = AgentState.ERROR
            return f"Error interno: {str(e)}"
    
    def create_and_execute_task(self, title: str, description: str, goal: str,
                               auto_execute: bool = True) -> str:
        """
        Crea y opcionalmente ejecuta una nueva tarea con generaci√≥n robusta de planes
        Implementa mejoras seg√∫n UPGRADE.md Problema 1: Generaci√≥n de Planes Gen√©ricos
        """
        try:
            self.state = AgentState.PLANNING
            
            # Generar plan usando la nueva funci√≥n robusta
            plan_data = self._generate_robust_plan_with_retries(title, description, goal)
            
            if not plan_data:
                return "Error: No se pudo generar un plan v√°lido para la tarea."
            
            # Crear tarea
            task_id = self.task_manager.create_task(
                title=title,
                description=description,
                goal=goal,
                phases=plan_data.get("phases", []),
                context={"plan_response": plan_data.get("_original_response", ""), "ai_generated": True}
            )
            
            # A√±adir informaci√≥n a la memoria
            self.memory_manager.add_knowledge(
                content=f"Tarea creada: {title} - {description}",
                category="task_planning",
                source="agent_planning",
                confidence=0.9,
                tags=["task", "planning"]
            )
            
            if auto_execute:
                # Iniciar ejecuci√≥n de la tarea
                if self.task_manager.start_task(task_id):
                    self.state = AgentState.EXECUTING
                    return f"Tarea '{title}' creada e iniciada con ID: {task_id}"
                else:
                    return f"Tarea '{title}' creada con ID: {task_id}, pero no se pudo iniciar autom√°ticamente."
            else:
                return f"Tarea '{title}' creada con ID: {task_id}. Usa start_task() para ejecutar."
            
        except Exception as e:
            self.logger.error(f"Error al crear y ejecutar tarea: {e}")
            self.state = AgentState.ERROR
            return f"Error al crear tarea: {str(e)}"
    
    def _generate_robust_plan_with_retries(self, title: str, description: str, goal: str, 
                                         max_attempts: int = 3) -> Optional[Dict[str, Any]]:
        """
        Genera un plan robusto con reintentos y validaci√≥n de esquemas
        Implementa mejoras seg√∫n UPGRADE.md Problema 1: Validaci√≥n y Reintento Robusto
        """
        last_error = None
        
        for attempt in range(1, max_attempts + 1):
            try:
                self.logger.info(f"Generando plan - Intento {attempt}/{max_attempts}")
                
                # Generar prompt espec√≠fico seg√∫n el intento
                if attempt == 1:
                    # Primera tentativa: prompt con ejemplos (few-shot learning)
                    planning_prompt = self._create_coercive_planning_prompt(title, description, goal)
                elif attempt == 2:
                    # Segunda tentativa: prompt con correcci√≥n espec√≠fica
                    planning_prompt = self._create_correction_prompt(title, description, goal, last_error)
                else:
                    # Tercera tentativa: prompt simplificado de emergencia
                    planning_prompt = self._create_emergency_fallback_prompt(title, description, goal)
                
                # Seleccionar modelo optimizado para JSON
                planning_model = self.model_manager.select_best_model(
                    task_type="analysis",
                    max_cost=self.config.max_cost_per_1k_tokens
                )
                
                if not planning_model:
                    last_error = "No hay modelos disponibles para planificaci√≥n"
                    continue
                
                # Generar respuesta
                plan_response = self.model_manager.generate_response(
                    planning_prompt,
                    model=planning_model,
                    max_tokens=1500,
                    temperature=0.2  # Temperatura baja para mayor consistencia
                )
                
                if not plan_response:
                    last_error = "El modelo no gener√≥ respuesta"
                    continue
                
                # Parsear y validar con m√∫ltiples estrategias
                plan_data = self._parse_and_validate_plan(plan_response)
                
                if plan_data:
                    # √âxito! Registrar rendimiento del prompt
                    self._record_prompt_performance(attempt, True, plan_response)
                    plan_data["_original_response"] = plan_response
                    plan_data["_generation_attempt"] = attempt
                    return plan_data
                else:
                    last_error = "JSON generado no cumple con el esquema requerido"
                    
            except Exception as e:
                last_error = f"Error inesperado: {str(e)}"
                self.logger.error(f"Error en intento {attempt}: {e}")
                
            # Registrar fallo
            self._record_prompt_performance(attempt, False, "")
        
        # Si llegamos aqu√≠, todos los intentos fallaron
        self.logger.error(f"Fall√≥ generaci√≥n de plan despu√©s de {max_attempts} intentos. √öltimo error: {last_error}")
        
        # Generar plan de respaldo SOLO despu√©s de agotar reintentos
        self.logger.warning("Generando plan de respaldo gen√©rico como √∫ltimo recurso")
        fallback_plan = self._create_fallback_plan_with_notification(title, description, goal, last_error)
        return fallback_plan
    
    def _create_coercive_planning_prompt(self, title: str, description: str, goal: str) -> str:
        """
        Crea un prompt coercitivo con ejemplos seg√∫n UPGRADE.md
        Incluye instrucciones m√°s imperativas y ejemplos en contexto (few-shot learning)
        """
        return f"""¬°ADVERTENCIA! La respuesta DEBE ser un JSON v√°lido y nada m√°s. No incluyas texto explicativo antes o despu√©s del JSON.

TAREA: {title}
DESCRIPCI√ìN: {description}
OBJETIVO: {goal}

EJEMPLOS DE FORMATO CORRECTO:

Ejemplo 1 - An√°lisis:
{{"goal": "Analizar tendencias de IA en 2025", "phases": [{{"id": 1, "title": "Investigaci√≥n de fuentes actuales", "description": "Buscar informaci√≥n actualizada sobre IA en 2025", "required_capabilities": ["web_search"], "tool_name": "web_search"}}, {{"id": 2, "title": "An√°lisis de datos encontrados", "description": "Procesar y analizar la informaci√≥n recolectada", "required_capabilities": ["analysis"], "tool_name": "analysis"}}, {{"id": 3, "title": "Redacci√≥n de informe detallado", "description": "Crear documento con conclusiones y tendencias identificadas", "required_capabilities": ["creation"], "tool_name": "creation"}}]}}

Ejemplo 2 - Creaci√≥n:
{{"goal": "Crear script de automatizaci√≥n", "phases": [{{"id": 1, "title": "Definici√≥n de requisitos t√©cnicos", "description": "Identificar funcionalidades espec√≠ficas requeridas", "required_capabilities": ["analysis"], "tool_name": "analysis"}}, {{"id": 2, "title": "Desarrollo del c√≥digo fuente", "description": "Escribir el script con las funcionalidades definidas", "required_capabilities": ["creation"], "tool_name": "creation"}}, {{"id": 3, "title": "Pruebas y optimizaci√≥n final", "description": "Validar funcionamiento y optimizar rendimiento", "required_capabilities": ["analysis"], "tool_name": "analysis"}}]}}

AHORA GENERA EL JSON PARA LA TAREA ACTUAL. Debe ser espec√≠fico, NO gen√©rico como "An√°lisis", "Ejecuci√≥n", "Entrega".

ESQUEMA REQUERIDO:
- "goal": string (m√≠nimo 3 caracteres)
- "phases": array de 1-10 objetos
  - Cada fase DEBE tener: "id" (integer), "title" (5-100 chars), "description" (10-300 chars), "required_capabilities" (array), "tool_name" (string)
  - Herramientas v√°lidas: "web_search", "file_write", "analysis", "creation", "shell_exec", "general"

RESPUESTA (SOLO JSON):"""

    def _create_correction_prompt(self, title: str, description: str, goal: str, error: str) -> str:
        """
        Crea un prompt de correcci√≥n espec√≠fica seg√∫n UPGRADE.md
        """
        return f"""El JSON anterior tuvo errores. ERROR: {error}

Por favor, corrige el JSON y aseg√∫rate de que cumpla con el esquema.

TAREA: {title}
OBJETIVO: {goal}

FORMATO CORRECTO REQUERIDO:
{{"goal": "objetivo espec√≠fico aqu√≠", "phases": [{{"id": 1, "title": "t√≠tulo espec√≠fico NO gen√©rico", "description": "descripci√≥n detallada de 10-300 caracteres", "required_capabilities": ["capability"], "tool_name": "herramienta_v√°lida"}}]}}

HERRAMIENTAS V√ÅLIDAS: web_search, file_write, analysis, creation, shell_exec, general
CAPACIDADES V√ÅLIDAS: analysis, web_search, creation, planning, delivery, processing, synthesis, general, communication

NO uses t√≠tulos gen√©ricos como "An√°lisis", "Ejecuci√≥n", "Entrega". S√© espec√≠fico para esta tarea.

RESPUESTA CORREGIDA (SOLO JSON):"""

    def _create_emergency_fallback_prompt(self, title: str, description: str, goal: str) -> str:
        """
        Crea un prompt simplificado de emergencia
        """
        return f"""Genera SOLO este JSON v√°lido para: {title}

{{"goal": "completar la tarea solicitada", "phases": [{{"id": 1, "title": "Procesar solicitud espec√≠fica", "description": "Analizar y procesar la solicitud del usuario de manera espec√≠fica", "required_capabilities": ["analysis"], "tool_name": "analysis"}}, {{"id": 2, "title": "Ejecutar acciones necesarias", "description": "Realizar las acciones espec√≠ficas requeridas para completar la tarea", "required_capabilities": ["general"], "tool_name": "general"}}]}}

Pero personal√≠zalo para la tarea espec√≠fica: {description}

SOLO JSON, sin explicaciones:"""

    def _parse_and_validate_plan(self, plan_response: str) -> Optional[Dict[str, Any]]:
        """
        Parsea y valida el plan usando m√∫ltiples estrategias seg√∫n UPGRADE.md
        Implementa validaci√≥n de esquema post-generaci√≥n robusta
        """
        plan_data = None
        
        # Estrategia 1: JSON directo
        try:
            # Limpiar respuesta
            cleaned_response = plan_response.strip()
            if cleaned_response.startswith('{') and cleaned_response.endswith('}'):
                plan_data = json.loads(cleaned_response)
        except json.JSONDecodeError:
            pass
        
        # Estrategia 2: Buscar JSON en el texto
        if not plan_data:
            try:
                json_match = re.search(r'\{[^{}]*"goal"[^{}]*"phases"[^{}]*\[.*?\][^{}]*\}', plan_response, re.DOTALL)
                if json_match:
                    plan_data = json.loads(json_match.group())
            except json.JSONDecodeError:
                pass
        
        # Estrategia 3: JSON con correcci√≥n de formato
        if not plan_data:
            try:
                # Corregir comillas simples por dobles
                corrected_text = plan_response.replace("'", '"')
                # Buscar el JSON principal
                start_idx = corrected_text.find('{')
                end_idx = corrected_text.rfind('}') + 1
                if start_idx != -1 and end_idx != 0:
                    json_text = corrected_text[start_idx:end_idx]
                    plan_data = json.loads(json_text)
            except (json.JSONDecodeError, Exception):
                pass
        
        # Validar esquema usando jsonschema
        if plan_data:
            try:
                jsonschema.validate(plan_data, PLAN_SCHEMA)
                self.logger.info("Plan generado v√°lido seg√∫n esquema")
                return plan_data
            except jsonschema.ValidationError as e:
                self.logger.warning(f"Plan no cumple esquema: {e.message}")
                # Registrar error para an√°lisis futuro (aprendizaje)
                self._register_validation_error(plan_response, str(e))
        
        return None
    
    def _create_fallback_plan_with_notification(self, title: str, description: str, goal: str, reason: str) -> Dict[str, Any]:
        """
        Crea plan de respaldo solo despu√©s de agotar reintentos seg√∫n UPGRADE.md
        """
        self.logger.warning(f"Generando plan de respaldo para '{title}'. Raz√≥n: {reason}")
        
        return {
            "goal": goal,
            "phases": [
                {
                    "id": 1, 
                    "title": f"An√°lisis espec√≠fico: {title}", 
                    "description": f"Analizar los requisitos espec√≠ficos para: {description}", 
                    "required_capabilities": ["analysis"],
                    "tool_name": "analysis"
                },
                {
                    "id": 2, 
                    "title": f"Procesamiento de: {title}", 
                    "description": f"Procesar y trabajar en la tarea espec√≠fica: {description}", 
                    "required_capabilities": ["general"],
                    "tool_name": "general"
                },
                {
                    "id": 3, 
                    "title": f"Entrega final de: {title}", 
                    "description": f"Completar y entregar los resultados finales de: {description}", 
                    "required_capabilities": ["delivery"],
                    "tool_name": "general"
                }
            ],
            "_fallback_used": True,
            "_fallback_reason": reason,
            "_warning": "Este plan fue generado como respaldo despu√©s de m√∫ltiples intentos fallidos"
        }
    
    def _record_prompt_performance(self, attempt: int, success: bool, response: str):
        """
        Registra el rendimiento del prompt para an√°lisis futuro seg√∫n UPGRADE.md
        Utiliza m√©tricas de PromptPerformance para monitoreo
        """
        try:
            # Aqu√≠ se integrar√≠a con enhanced_prompts.py para registrar m√©tricas
            performance_data = {
                "attempt": attempt,
                "success": success,
                "response_length": len(response) if response else 0,
                "timestamp": time.time()
            }
            
            # A√±adir a memoria para an√°lisis futuro
            self.memory_manager.add_knowledge(
                content=f"Prompt performance: {performance_data}",
                category="prompt_optimization",
                source="agent_planning",
                confidence=1.0,
                tags=["performance", "planning", "optimization"]
            )
            
        except Exception as e:
            self.logger.error(f"Error registrando performance: {e}")
    
    def _register_validation_error(self, response: str, error: str):
        """
        Registra errores de validaci√≥n para an√°lisis futuro seg√∫n UPGRADE.md
        """
        try:
            self.memory_manager.add_knowledge(
                content=f"Validation error: {error} | Response: {response[:200]}...",
                category="validation_errors",
                source="agent_planning",
                confidence=0.8,
                tags=["error", "validation", "planning"]
            )
        except Exception as e:
            self.logger.error(f"Error registrando validation error: {e}")
    
    def execute_current_phase(self, task_id: Optional[str] = None) -> str:
        """
        Ejecuta la fase actual de una tarea con herramientas reales
        Implementa mejoras seg√∫n UPGRADE.md Problema 2: Despachador de Herramientas (Tool Dispatcher)
        """
        try:
            self.state = AgentState.EXECUTING
            
            # Obtener tarea actual o especificada
            if task_id:
                task = self.task_manager.get_task(task_id)
            else:
                task = self.task_manager.get_current_task()
            
            if not task:
                return "Error: No hay tarea activa para ejecutar."
            
            # Obtener fase actual
            current_phase = self.task_manager.get_current_phase(task.id)
            if not current_phase:
                return "Error: No hay fase activa en la tarea."
            
            # Generar prompt de ejecuci√≥n para tool calling
            execution_prompt = self._create_tool_calling_prompt(task, current_phase)
            
            # Seleccionar modelo apropiado para la fase
            task_type = self._determine_task_type_from_capabilities(current_phase.required_capabilities)
            execution_model = self.model_manager.select_best_model(
                task_type=task_type,
                max_cost=self.config.max_cost_per_1k_tokens
            )
            
            if not execution_model:
                return "Error: No hay modelos disponibles para ejecutar la fase."
            
            # Ejecutar fase con LLM para obtener tool call
            execution_response = self.model_manager.generate_response(
                execution_prompt,
                model=execution_model,
                max_tokens=2000,
                temperature=0.3  # Temperatura baja para tool calling preciso
            )
            
            if not execution_response:
                return "Error: No se pudo obtener respuesta para ejecutar la fase."
            
            # PASO CR√çTICO: Parsear y ejecutar herramientas reales
            tool_result = self._parse_and_execute_tools(execution_response, task, current_phase)
            
            if not tool_result:
                return "Error: No se pudo ejecutar ninguna herramienta v√°lida."
            
            # Actualizaci√≥n del progreso basada en resultados reales de herramientas
            if tool_result.get("status") == "success":
                # Avanzar a la siguiente fase bas√°ndose en √©xito de herramienta
                next_phase_id = current_phase.id + 1
                if next_phase_id <= len(task.phases):
                    self.task_manager.advance_phase(task.id, current_phase.id, next_phase_id, tool_result)
                    return f"Fase {current_phase.id} completada exitosamente con herramientas. Resultado: {tool_result.get('summary', '')}. Avanzando a fase {next_phase_id}."
                else:
                    # Completar tarea
                    self.task_manager.complete_task(task.id, tool_result)
                    self.stats["tasks_completed"] += 1
                    return f"Tarea '{task.title}' completada exitosamente. Resultado final: {tool_result.get('summary', '')}"
            elif tool_result.get("status") == "failure":
                # Manejar error de herramienta
                error_result = self._handle_tool_error(task, current_phase, tool_result.get("error", ""))
                return f"Error ejecutando fase {current_phase.id}: {error_result}"
            else:
                return f"Fase {current_phase.id} en progreso: {tool_result.get('summary', '')}"
            
        except Exception as e:
            self.logger.error(f"Error al ejecutar fase: {e}")
            self.state = AgentState.ERROR
            return f"Error al ejecutar fase: {str(e)}"
    
    def _create_tool_calling_prompt(self, task, current_phase) -> str:
        """
        Crea un prompt para tool calling seg√∫n UPGRADE.md
        Incluye descripciones de herramientas disponibles y esquemas de par√°metros
        """
        tools_registry = self._get_tools_registry()
        
        # Construir descripciones de herramientas disponibles
        tools_description = "\n".join([
            f"- {name}: {info['description']} | Par√°metros: {info['parameters']}"
            for name, info in tools_registry.items()
        ])
        
        return f"""Eres un agente que debe ejecutar esta fase de tarea usando herramientas reales.

TAREA: {task.title}
DESCRIPCI√ìN DE TAREA: {task.description}
OBJETIVO: {task.goal}

FASE ACTUAL:
- ID: {current_phase.id}
- T√≠tulo: {current_phase.title}
- Descripci√≥n: {current_phase.description}
- Capacidades requeridas: {current_phase.required_capabilities}

HERRAMIENTAS DISPONIBLES:
{tools_description}

INSTRUCCIONES:
Responde √öNICAMENTE con un JSON que contenga:
1. "action_type": "tool_call", "reflection", o "report"
2. Si es "tool_call":
   - "tool_name": nombre de la herramienta a usar
   - "tool_parameters": par√°metros espec√≠ficos para la herramienta
   - "thought": por qu√© usas esta herramienta
   - "status_update": mensaje de progreso para el usuario

EJEMPLO DE RESPUESTA:
{{"action_type": "tool_call", "tool_name": "web_search", "tool_parameters": {{"query": "tendencias IA 2025", "num_results": 5}}, "thought": "Necesito buscar informaci√≥n actualizada sobre IA", "status_update": "Buscando informaci√≥n sobre tendencias de IA"}}

Si la fase no requiere herramientas, usa:
{{"action_type": "report", "summary": "descripci√≥n del trabajo realizado", "status_update": "Fase completada"}}

RESPUESTA (SOLO JSON):"""
    
    def _get_tools_registry(self) -> Dict[str, Dict[str, Any]]:
        """
        Obtiene el registro central de herramientas seg√∫n UPGRADE.md
        Mapea nombres de herramientas a sus funciones reales y esquemas de par√°metros
        """
        return {
            "web_search": {
                "description": "Buscar informaci√≥n en la web",
                "parameters": {"query": "string", "num_results": "integer"},
                "function": self._execute_web_search
            },
            "file_write": {
                "description": "Escribir contenido a un archivo",
                "parameters": {"filename": "string", "content": "string"},
                "function": self._execute_file_write
            },
            "shell_exec": {
                "description": "Ejecutar comando de shell",
                "parameters": {"command": "string", "timeout": "integer"},
                "function": self._execute_shell_command
            },
            "analysis": {
                "description": "Realizar an√°lisis detallado",
                "parameters": {"data": "string", "analysis_type": "string"},
                "function": self._execute_analysis
            },
            "creation": {
                "description": "Crear contenido o documentos",
                "parameters": {"content_type": "string", "specifications": "string"},
                "function": self._execute_creation
            },
            "general": {
                "description": "Procesamiento general",
                "parameters": {"task_description": "string"},
                "function": self._execute_general_task
            }
        }
    
    def _parse_and_execute_tools(self, execution_response: str, task, current_phase) -> Dict[str, Any]:
        """
        Parsea la respuesta del LLM y ejecuta herramientas reales seg√∫n UPGRADE.md
        Implementa l√≥gica de despacho en execute_current_phase
        """
        try:
            # Parsear respuesta JSON del LLM
            tool_call_data = self._parse_tool_call_response(execution_response)
            
            if not tool_call_data:
                return {"status": "failure", "error": "No se pudo parsear llamada a herramienta"}
            
            action_type = tool_call_data.get("action_type")
            
            if action_type == "tool_call":
                tool_name = tool_call_data.get("tool_name")
                tool_parameters = tool_call_data.get("tool_parameters", {})
                thought = tool_call_data.get("thought", "")
                status_update = tool_call_data.get("status_update", "")
                
                # Validar herramienta en registry
                tools_registry = self._get_tools_registry()
                if tool_name not in tools_registry:
                    return {"status": "failure", "error": f"Herramienta '{tool_name}' no disponible"}
                
                # Validar par√°metros contra esquema de la herramienta
                tool_info = tools_registry[tool_name]
                if not self._validate_tool_parameters(tool_parameters, tool_info["parameters"]):
                    return {"status": "failure", "error": f"Par√°metros inv√°lidos para herramienta '{tool_name}'"}
                
                # Invocar la funci√≥n de la herramienta
                try:
                    self.logger.info(f"Ejecutando herramienta '{tool_name}' con par√°metros: {tool_parameters}")
                    tool_function = tool_info["function"]
                    result = tool_function(tool_parameters)
                    
                    # Registrar resultado de la herramienta en la memoria
                    self._register_tool_execution(tool_name, tool_parameters, result, task.id, current_phase.id)
                    
                    return {
                        "status": "success" if result.get("success", True) else "failure",
                        "tool_name": tool_name,
                        "tool_result": result,
                        "thought": thought,
                        "status_update": status_update,
                        "summary": result.get("summary", f"Herramienta '{tool_name}' ejecutada")
                    }
                    
                except Exception as tool_error:
                    self.logger.error(f"Error ejecutando herramienta '{tool_name}': {tool_error}")
                    return {"status": "failure", "error": str(tool_error), "tool_name": tool_name}
            
            elif action_type == "reflection":
                # Invocar funci√≥n de reflexi√≥n del agente
                reflection_result = self._handle_reflection(tool_call_data, task, current_phase)
                return {"status": "success", "summary": reflection_result, "action_type": "reflection"}
            
            elif action_type == "report":
                # La fase est√° completa sin herramientas
                summary = tool_call_data.get("summary", "Fase completada")
                return {"status": "success", "summary": summary, "action_type": "report"}
            
            else:
                return {"status": "failure", "error": f"Tipo de acci√≥n no reconocido: {action_type}"}
                
        except Exception as e:
            self.logger.error(f"Error parseando y ejecutando herramientas: {e}")
            return {"status": "failure", "error": str(e)}
    
    def _parse_tool_call_response(self, response: str) -> Optional[Dict[str, Any]]:
        """
        Parsea la respuesta JSON del LLM con m√∫ltiples estrategias
        """
        tool_data = None
        
        # Estrategia 1: JSON directo
        try:
            cleaned_response = response.strip()
            if cleaned_response.startswith('{') and cleaned_response.endswith('}'):
                tool_data = json.loads(cleaned_response)
        except json.JSONDecodeError:
            pass
        
        # Estrategia 2: Buscar JSON en el texto
        if not tool_data:
            try:
                json_match = re.search(r'\{[^{}]*"action_type"[^{}]*\}', response, re.DOTALL)
                if json_match:
                    tool_data = json.loads(json_match.group())
            except json.JSONDecodeError:
                pass
        
        # Estrategia 3: JSON con correcci√≥n de formato
        if not tool_data:
            try:
                corrected_text = response.replace("'", '"')
                start_idx = corrected_text.find('{')
                end_idx = corrected_text.rfind('}') + 1
                if start_idx != -1 and end_idx != 0:
                    json_text = corrected_text[start_idx:end_idx]
                    tool_data = json.loads(json_text)
            except (json.JSONDecodeError, Exception):
                pass
        
        return tool_data
    
    def _validate_tool_parameters(self, parameters: Dict[str, Any], schema: Dict[str, str]) -> bool:
        """
        Valida par√°metros de herramienta contra esquema
        """
        try:
            for param_name, param_type in schema.items():
                if param_name not in parameters:
                    return False
                
                param_value = parameters[param_name]
                if param_type == "string" and not isinstance(param_value, str):
                    return False
                elif param_type == "integer" and not isinstance(param_value, int):
                    return False
            
            return True
        except Exception:
            return False
    
    def _handle_tool_error(self, task, current_phase, error: str) -> str:
        """
        Maneja errores de herramientas seg√∫n UPGRADE.md
        Implementa estrategias de recuperaci√≥n
        """
        try:
            # Generar prompt de recuperaci√≥n
            recovery_prompt = f"""ERROR AL EJECUTAR HERRAMIENTA: {error}

CONTEXTO:
- Tarea: {task.title}
- Fase: {current_phase.title}
- Error: {error}

Sugiere una estrategia de recuperaci√≥n. Opciones:
1. Reintentar con diferentes par√°metros
2. Usar herramienta alternativa
3. Pedir ayuda al usuario
4. Marcar fase como fallida

Responde con JSON: {{"strategy": "retry|alternative|ask_user|fail", "details": "explicaci√≥n", "new_action": "acci√≥n espec√≠fica"}}"""

            # Usar modelo para estrategia de recuperaci√≥n
            model = self.model_manager.select_best_model(task_type="analysis")
            if model:
                recovery_response = self.model_manager.generate_response(
                    recovery_prompt, model=model, max_tokens=500, temperature=0.3
                )
                
                # Implementar estrategia de recuperaci√≥n b√°sica
                if recovery_response and "retry" in recovery_response.lower():
                    return f"Reintentando fase despu√©s de error: {error}"
                elif recovery_response and "alternative" in recovery_response.lower():
                    return f"Buscando herramienta alternativa despu√©s de error: {error}"
            
            return f"Error en herramienta: {error}. Se requiere intervenci√≥n manual."
            
        except Exception as e:
            self.logger.error(f"Error en manejo de errores: {e}")
            return f"Error cr√≠tico: {error}"
    
    def _register_tool_execution(self, tool_name: str, parameters: Dict[str, Any], 
                               result: Dict[str, Any], task_id: str, phase_id: int):
        """
        Registra la ejecuci√≥n de herramienta en la memoria del agente
        """
        try:
            execution_record = {
                "tool_name": tool_name,
                "parameters": parameters,
                "result": result,
                "task_id": task_id,
                "phase_id": phase_id,
                "timestamp": time.time()
            }
            
            self.memory_manager.add_knowledge(
                content=f"Tool execution: {tool_name} - {result.get('summary', 'executed')}",
                category="tool_execution",
                source="agent_execution",
                confidence=0.9,
                tags=["tool", "execution", tool_name]
            )
            
        except Exception as e:
            self.logger.error(f"Error registrando ejecuci√≥n de herramienta: {e}")
    
    def _handle_reflection(self, reflection_data: Dict[str, Any], task, current_phase) -> str:
        """
        Maneja reflexiones del agente
        """
        try:
            reflection_content = reflection_data.get("reflection", "Reflexi√≥n realizada")
            
            # A√±adir reflexi√≥n a la memoria
            self.memory_manager.add_knowledge(
                content=f"Reflection on phase {current_phase.id}: {reflection_content}",
                category="reflections",
                source="agent_reflection",
                confidence=0.8,
                tags=["reflection", "phase", str(current_phase.id)]
            )
            
            return f"Reflexi√≥n completada: {reflection_content}"
            
        except Exception as e:
            self.logger.error(f"Error en reflexi√≥n: {e}")
            return "Error en reflexi√≥n"
    
    # IMPLEMENTACIONES DE HERRAMIENTAS REALES seg√∫n UPGRADE.md Problema 2
    async def _execute_web_search_async(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta b√∫squeda web real con WebBrowserManager
        NUEVA IMPLEMENTACI√ìN - NEWUPGRADE.md Fase 2: Reemplaza mockups con Playwright real
        """
        try:
            query = parameters.get("query", "")
            num_results = parameters.get("num_results", 5)
            
            if not query:
                return {"success": False, "error": "Query is required", "summary": "Error: b√∫squeda sin query"}
            
            self.logger.info(f"üåê Ejecutando b√∫squeda web real para: '{query}' (m√°ximo {num_results} resultados)")
            
            # USAR WEBbrowsermanager REAL
            try:
                # Inicializar navegador si no est√° listo
                if not self.web_browser_manager.browser:
                    initialized = await self.web_browser_manager.initialize()
                    if not initialized:
                        # Fallback a b√∫squeda simple si falla la inicializaci√≥n
                        self.logger.warning("Navegador no disponible, usando fallback simple")
                        return await self._execute_web_search_fallback(query, num_results)
                
                # Ejecutar b√∫squeda web real
                scraping_result = await self.web_browser_manager.search_web(query, num_results)
                
                if not scraping_result.success:
                    self.logger.warning(f"B√∫squeda web fall√≥: {scraping_result.error_message}")
                    return await self._execute_web_search_fallback(query, num_results)
                
                # Procesar resultados
                search_results = []
                for i, page in enumerate(scraping_result.pages[:num_results]):
                    if page.error:
                        self.logger.warning(f"Error en p√°gina {page.url}: {page.error}")
                        continue
                    
                    # Limpiar y resumir contenido
                    content_summary = page.content[:300] + "..." if len(page.content) > 300 else page.content
                    content_summary = content_summary.replace('\n', ' ').strip()
                    
                    search_results.append({
                        "title": page.title or f"Resultado {i+1}",
                        "url": page.url,
                        "snippet": content_summary,
                        "loading_time": page.loading_time,
                        "scraped_at": page.timestamp.isoformat() if page.timestamp else None
                    })
                
                if not search_results:
                    return {
                        "success": False,
                        "error": "No se obtuvieron resultados v√°lidos",
                        "summary": f"B√∫squeda completada pero sin resultados √∫tiles para '{query}'"
                    }
                
                # Registrar en memoria como conocimiento
                knowledge_content = f"B√∫squeda web: {query}\nResultados encontrados: {len(search_results)}"
                self.memory_manager.add_knowledge(
                    content=knowledge_content,
                    category="web_search",
                    source="web_browser_manager",
                    confidence=0.8,
                    tags=["search", "web", "real"]
                )
                
                return {
                    "success": True,
                    "search_results": search_results,
                    "query": query,
                    "num_results": len(search_results),
                    "processing_time": scraping_result.processing_time,
                    "cache_hits": scraping_result.cache_hits,
                    "summary": f"B√∫squeda web REAL completada: encontradas {len(search_results)} fuentes sobre '{query}'"
                }
                
            except Exception as e:
                self.logger.error(f"Error en b√∫squeda web real: {e}")
                return await self._execute_web_search_fallback(query, num_results)
                
        except Exception as e:
            self.logger.error(f"Error cr√≠tico en b√∫squeda web: {e}")
            return {"success": False, "error": str(e), "summary": f"Error en b√∫squeda web: {str(e)}"}

    def _execute_web_search(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Wrapper sincr√≥nico para _execute_web_search_async
        Mantiene compatibilidad con el sistema de herramientas existente
        """
        import asyncio
        
        try:
            # Ejecutar versi√≥n as√≠ncrona
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            result = loop.run_until_complete(self._execute_web_search_async(parameters))
            loop.close()
            return result
            
        except Exception as e:
            self.logger.error(f"Error ejecutando b√∫squeda web as√≠ncrona: {e}")
            # Fallback final a implementaci√≥n simple
            return asyncio.run(self._execute_web_search_fallback(
                parameters.get("query", ""), 
                parameters.get("num_results", 5)
            ))

    async def _execute_web_search_fallback(self, query: str, num_results: int) -> Dict[str, Any]:
        """
        Fallback cuando el navegador principal no est√° disponible
        Usa b√∫squeda simple sin navegador completo
        """
        try:
            self.logger.info(f"üîÑ Usando fallback de b√∫squeda para: '{query}'")
            
            # Usar funci√≥n simple de b√∫squeda web
            content = await search_web_simple(query, num_results)
            
            if "Error" in content:
                return {
                    "success": False,
                    "error": content,
                    "summary": f"Fallback fall√≥ para '{query}'"
                }
            
            # Simular formato de resultados para compatibilidad
            mock_results = [
                {
                    "title": f"Resultado de b√∫squeda {i+1}: {query}",
                    "url": f"https://search-result-{i+1}.com",
                    "snippet": content[:200] + "..." if len(content) > 200 else content
                }
                for i in range(min(num_results, 3))  # Limitar fallback a 3 resultados
            ]
            
            return {
                "success": True,
                "search_results": mock_results,
                "query": query,
                "num_results": len(mock_results),
                "fallback_used": True,
                "summary": f"B√∫squeda fallback completada para '{query}' (navegador no disponible)"
            }
            
        except Exception as e:
            self.logger.error(f"Error en fallback de b√∫squeda: {e}")
            return {
                "success": False,
                "error": str(e),
                "summary": f"Error cr√≠tico en fallback para '{query}'"
            }
    
    def _execute_file_write(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta escritura de archivo real
        Produce resultados tangibles seg√∫n UPGRADE.md
        """
        try:
            filename = parameters.get("filename", "output.txt")
            content = parameters.get("content", "")
            
            if not content:
                return {"success": False, "error": "Content is required", "summary": "Error: no hay contenido para escribir"}
            
            # Crear directorio si no existe
            output_dir = "generated_files"
            os.makedirs(output_dir, exist_ok=True)
            
            # Escribir archivo real
            filepath = os.path.join(output_dir, filename)
            with open(filepath, 'w', encoding='utf-8') as f:
                f.write(content)
            
            # Verificar que se cre√≥ el archivo
            if os.path.exists(filepath):
                file_size = os.path.getsize(filepath)
                return {
                    "success": True,
                    "filepath": filepath,
                    "filename": filename,
                    "file_size": file_size,
                    "summary": f"Archivo '{filename}' creado exitosamente ({file_size} bytes)"
                }
            else:
                return {"success": False, "error": "File was not created", "summary": "Error: no se pudo crear el archivo"}
            
        except Exception as e:
            return {"success": False, "error": str(e), "summary": f"Error escribiendo archivo: {str(e)}"}
    
    def _execute_shell_command(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta comando de shell real (con restricciones de seguridad)
        """
        try:
            command = parameters.get("command", "")
            timeout = parameters.get("timeout", 30)
            
            if not command:
                return {"success": False, "error": "Command is required", "summary": "Error: comando vac√≠o"}
            
            # Lista de comandos seguros permitidos
            safe_commands = ["ls", "pwd", "whoami", "date", "echo", "cat", "head", "tail", "wc"]
            command_parts = command.split()
            
            if not command_parts or command_parts[0] not in safe_commands:
                return {
                    "success": False, 
                    "error": "Command not allowed for security reasons",
                    "summary": f"Comando '{command}' no permitido por seguridad"
                }
            
            # Ejecutar comando seguro
            import subprocess
            result = subprocess.run(
                command, 
                shell=True, 
                capture_output=True, 
                text=True, 
                timeout=timeout
            )
            
            return {
                "success": result.returncode == 0,
                "command": command,
                "return_code": result.returncode,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "summary": f"Comando '{command}' ejecutado (c√≥digo: {result.returncode})"
            }
            
        except subprocess.TimeoutExpired:
            return {"success": False, "error": "Command timed out", "summary": f"Comando '{command}' excedi√≥ timeout"}
        except Exception as e:
            return {"success": False, "error": str(e), "summary": f"Error ejecutando comando: {str(e)}"}
    
    def _execute_analysis(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta an√°lisis detallado usando LLM
        """
        try:
            data = parameters.get("data", "")
            analysis_type = parameters.get("analysis_type", "general")
            
            if not data:
                return {"success": False, "error": "Data is required for analysis", "summary": "Error: no hay datos para analizar"}
            
            # Crear prompt de an√°lisis espec√≠fico
            analysis_prompt = f"""Realiza un an√°lisis {analysis_type} detallado de los siguientes datos:

DATOS:
{data}

TIPO DE AN√ÅLISIS: {analysis_type}

Proporciona:
1. Resumen ejecutivo
2. Hallazgos principales
3. Patrones identificados
4. Recomendaciones
5. Conclusiones

Formato: Respuesta estructurada y profesional."""
            
            # Usar modelo para an√°lisis
            model = self.model_manager.select_best_model(task_type="analysis")
            if not model:
                return {"success": False, "error": "No model available", "summary": "Error: no hay modelo disponible para an√°lisis"}
            
            analysis_result = self.model_manager.generate_response(
                analysis_prompt,
                model=model,
                max_tokens=2000,
                temperature=0.3
            )
            
            if analysis_result:
                return {
                    "success": True,
                    "analysis_type": analysis_type,
                    "analysis_result": analysis_result,
                    "data_analyzed": len(data),
                    "summary": f"An√°lisis {analysis_type} completado exitosamente"
                }
            else:
                return {"success": False, "error": "Analysis failed", "summary": "Error: fall√≥ el an√°lisis"}
            
        except Exception as e:
            return {"success": False, "error": str(e), "summary": f"Error en an√°lisis: {str(e)}"}
    
    def _execute_creation(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta creaci√≥n de contenido usando LLM
        """
        try:
            content_type = parameters.get("content_type", "document")
            specifications = parameters.get("specifications", "")
            
            if not specifications:
                return {"success": False, "error": "Specifications are required", "summary": "Error: no hay especificaciones para la creaci√≥n"}
            
            # Crear prompt de creaci√≥n espec√≠fico
            creation_prompt = f"""Crea {content_type} seg√∫n las siguientes especificaciones:

ESPECIFICACIONES:
{specifications}

TIPO DE CONTENIDO: {content_type}

Requisitos:
- Contenido original y espec√≠fico
- Alta calidad y profesionalismo
- Cumplir exactamente con las especificaciones
- Formato apropiado para el tipo de contenido

Genera el contenido completo y funcional."""
            
            # Usar modelo para creaci√≥n
            model = self.model_manager.select_best_model(task_type="code" if "code" in content_type.lower() else "general")
            if not model:
                return {"success": False, "error": "No model available", "summary": "Error: no hay modelo disponible para creaci√≥n"}
            
            created_content = self.model_manager.generate_response(
                creation_prompt,
                model=model,
                max_tokens=3000,
                temperature=0.7
            )
            
            if created_content:
                # Guardar contenido creado como archivo
                filename = f"{content_type}_{int(time.time())}.txt"
                file_result = self._execute_file_write({
                    "filename": filename,
                    "content": created_content
                })
                
                return {
                    "success": True,
                    "content_type": content_type,
                    "created_content": created_content,
                    "content_length": len(created_content),
                    "file_created": file_result.get("success", False),
                    "filename": filename if file_result.get("success") else None,
                    "summary": f"Creaci√≥n de {content_type} completada exitosamente"
                }
            else:
                return {"success": False, "error": "Creation failed", "summary": "Error: fall√≥ la creaci√≥n de contenido"}
            
        except Exception as e:
            return {"success": False, "error": str(e), "summary": f"Error en creaci√≥n: {str(e)}"}
    
    def _execute_general_task(self, parameters: Dict[str, Any]) -> Dict[str, Any]:
        """
        Ejecuta tarea general
        """
        try:
            task_description = parameters.get("task_description", "")
            
            if not task_description:
                return {"success": False, "error": "Task description is required", "summary": "Error: no hay descripci√≥n de tarea"}
            
            # Procesar tarea general
            general_prompt = f"""Procesa la siguiente tarea general:

DESCRIPCI√ìN DE TAREA:
{task_description}

Proporciona:
1. Comprensi√≥n de la tarea
2. Pasos realizados
3. Resultado obtenido
4. Estado de completitud

Responde de manera profesional y detallada."""
            
            # Usar modelo general
            model = self.model_manager.select_best_model(task_type="general")
            if not model:
                return {"success": False, "error": "No model available", "summary": "Error: no hay modelo disponible"}
            
            general_result = self.model_manager.generate_response(
                general_prompt,
                model=model,
                max_tokens=1500,
                temperature=0.5
            )
            
            if general_result:
                return {
                    "success": True,
                    "task_description": task_description,
                    "task_result": general_result,
                    "summary": "Tarea general completada exitosamente"
                }
            else:
                return {"success": False, "error": "General task failed", "summary": "Error: fall√≥ la tarea general"}
            
        except Exception as e:
            return {"success": False, "error": str(e), "summary": f"Error en tarea general: {str(e)}"}
    
    def reflect_on_action(self, action: str, result: str, expected: str) -> str:
        """Reflexiona sobre una acci√≥n ejecutada"""
        try:
            self.state = AgentState.REFLECTING
            
            # Obtener contexto de tarea actual
            current_task = self.task_manager.get_current_task()
            task_context = ""
            if current_task:
                task_context = f"Tarea: {current_task.title}\nObjetivo: {current_task.goal}"
            
            # Generar prompt de reflexi√≥n
            reflection_prompt = self.prompt_manager.generate_reflection_prompt(
                action_taken=action,
                result=result,
                expected_outcome=expected,
                task_context=task_context
            )
            
            # Seleccionar modelo para reflexi√≥n
            reflection_model = self.model_manager.select_best_model(
                task_type="analysis",
                max_cost=self.config.max_cost_per_1k_tokens
            )
            
            if not reflection_model:
                return "Error: No hay modelos disponibles para reflexi√≥n."
            
            # Generar reflexi√≥n
            reflection_response = self.model_manager.generate_response(
                reflection_prompt,
                model=reflection_model,
                max_tokens=800,
                temperature=0.6
            )
            
            if reflection_response:
                # A√±adir reflexi√≥n a la memoria como conocimiento
                self.memory_manager.add_knowledge(
                    content=f"Reflexi√≥n sobre acci√≥n: {action} -> {reflection_response}",
                    category="reflection",
                    source="agent_reflection",
                    confidence=0.8,
                    tags=["reflection", "learning"]
                )
                
                self.state = AgentState.IDLE
                return reflection_response
            else:
                return "Error: No se pudo generar reflexi√≥n."
            
        except Exception as e:
            self.logger.error(f"Error en reflexi√≥n: {e}")
            self.state = AgentState.ERROR
            return f"Error en reflexi√≥n: {str(e)}"
    
    def handle_error(self, error_message: str, failed_action: str, context: str = "") -> str:
        """Maneja errores y genera estrategias de recuperaci√≥n"""
        try:
            self.state = AgentState.ERROR
            
            # Generar prompt de manejo de errores
            error_prompt = self.prompt_manager.generate_error_handling_prompt(
                error_message=error_message,
                failed_action=failed_action,
                context=context,
                additional_info=f"Estado del agente: {self.state.value}"
            )
            
            # Seleccionar modelo para manejo de errores
            error_model = self.model_manager.select_best_model(
                task_type="analysis",
                max_cost=self.config.max_cost_per_1k_tokens
            )
            
            if not error_model:
                self.state = AgentState.IDLE
                return "Error cr√≠tico: No hay modelos disponibles para manejo de errores."
            
            # Generar estrategia de recuperaci√≥n
            recovery_response = self.model_manager.generate_response(
                error_prompt,
                model=error_model,
                max_tokens=1000,
                temperature=0.4
            )
            
            if recovery_response:
                # Registrar error y estrategia en memoria
                self.memory_manager.add_knowledge(
                    content=f"Error manejado: {error_message} -> Estrategia: {recovery_response}",
                    category="error_handling",
                    source="agent_error_handler",
                    confidence=0.7,
                    tags=["error", "recovery", "learning"]
                )
                
                self.state = AgentState.IDLE
                return recovery_response
            else:
                self.state = AgentState.IDLE
                return "Error: No se pudo generar estrategia de recuperaci√≥n."
            
        except Exception as e:
            self.logger.error(f"Error en manejo de errores: {e}")
            self.state = AgentState.IDLE
            return f"Error cr√≠tico en manejo de errores: {str(e)}"
    
    def _extract_knowledge_from_conversation(self, user_message: str, agent_response: str):
        """Extrae conocimiento relevante de la conversaci√≥n"""
        try:
            # Identificar si la conversaci√≥n contiene informaci√≥n valiosa
            knowledge_indicators = [
                "aprend√≠", "descubr√≠", "encontr√©", "resultado", "soluci√≥n",
                "importante", "clave", "fundamental", "t√©cnica", "m√©todo"
            ]
            
            combined_text = (user_message + " " + agent_response).lower()
            
            if any(indicator in combined_text for indicator in knowledge_indicators):
                # Extraer conocimiento
                knowledge_content = f"Conversaci√≥n: Usuario pregunt√≥ sobre '{user_message[:100]}...' y se determin√≥: {agent_response[:200]}..."
                
                self.memory_manager.add_knowledge(
                    content=knowledge_content,
                    category="conversation",
                    source="user_interaction",
                    confidence=0.6,
                    tags=["conversation", "user_query"]
                )
                
        except Exception as e:
            self.logger.error(f"Error al extraer conocimiento: {e}")
    
    def _determine_task_type_from_capabilities(self, capabilities: List[str]) -> str:
        """Determina el tipo de tarea bas√°ndose en las capacidades requeridas"""
        capability_mapping = {
            "code": ["code_generation", "programming", "development"],
            "analysis": ["analysis", "research", "investigation"],
            "chat": ["communication", "interaction", "conversation"],
            "general": ["general", "misc", "other"]
        }
        
        for task_type, keywords in capability_mapping.items():
            if any(keyword in cap.lower() for cap in capabilities for keyword in keywords):
                return task_type
        
        return "general"
    
    def get_status(self) -> Dict[str, Any]:
        """Obtiene el estado completo del agente"""
        self.stats["uptime"] = time.time() - self.startup_time
        
        return {
            "agent_name": self.config.agent_name,
            "state": self.state.value,
            "session_id": self.current_session_id,
            "uptime_seconds": self.stats["uptime"],
            "statistics": self.stats.copy(),
            "memory_stats": self.memory_manager.get_memory_stats(),
            "task_manager_status": self.task_manager.get_manager_status(),
            "model_manager_status": self.model_manager.get_status(),
            "available_models": len(self.model_manager.get_available_models())
        }
    
    def shutdown(self):
        """Cierra el agente de manera ordenada"""
        try:
            self.logger.info("Iniciando cierre del agente...")
            
            # Persistir memoria a corto plazo
            self.memory_manager.clear_short_term_memory(persist=True)
            
            # Detener monitoreo de tareas
            self.task_manager._stop_monitoring_thread()
            
            # Limpiar datos antiguos
            self.memory_manager.cleanup_old_data(days_old=30)
            
            self.state = AgentState.IDLE
            self.logger.info("Agente cerrado correctamente")
            
        except Exception as e:
            self.logger.error(f"Error durante el cierre: {e}")

# Funci√≥n de conveniencia para crear un agente con configuraci√≥n por defecto
def create_mitosis_agent(ollama_url: str = "http://localhost:11434",
                        openrouter_api_key: Optional[str] = None,
                        prefer_local: bool = True) -> MitosisAgent:
    """Crea una instancia del agente Mitosis con configuraci√≥n b√°sica"""
    config = AgentConfig(
        ollama_url=ollama_url,
        openrouter_api_key=openrouter_api_key,
        prefer_local_models=prefer_local
    )
    return MitosisAgent(config)

# Ejemplo de uso
if __name__ == "__main__":
    # Crear agente
    agent = create_mitosis_agent()
    
    # Iniciar sesi√≥n
    session_id = agent.start_session()
    print(f"üöÄ Sesi√≥n iniciada: {session_id}")
    
    # Procesar mensaje del usuario
    response = agent.process_user_message("Hola, ¬øpuedes ayudarme a crear un script de Python?")
    print(f"ü§ñ Respuesta: {response}")
    
    # Crear y ejecutar una tarea
    task_result = agent.create_and_execute_task(
        title="Crear script de Python",
        description="Desarrollar un script que procese archivos CSV",
        goal="Crear un script funcional para procesamiento de datos CSV"
    )
    print(f"üìã Resultado de tarea: {task_result}")
    
    # Obtener estado del agente
    status = agent.get_status()
    print(f"üìä Estado del agente: {status['state']}")
    print(f"üìà Mensajes procesados: {status['statistics']['messages_processed']}")
    
    # Cerrar agente
    agent.shutdown()
    print("‚úÖ Agente cerrado correctamente")


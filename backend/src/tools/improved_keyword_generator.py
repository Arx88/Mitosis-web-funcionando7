"""
ðŸ§  GENERADOR INTELIGENTE DE KEYWORDS - SOLUCIÃ“N COMPLETA V2.0
Reemplaza la lÃ³gica destructiva de _extract_clean_keywords_static()
con un sistema inteligente que preserva el contexto esencial

RESUELVE: 
- Keywords inÃºtiles como "REALIZA INFORME"
- PÃ©rdida de contexto importante
- BÃºsquedas genÃ©ricas sin resultados

IMPLEMENTA:
- PreservaciÃ³n de entidades nombradas (personas, lugares)
- ExtracciÃ³n inteligente de conceptos principales
- MÃºltiples variantes de bÃºsqueda especÃ­ficas
- Contexto temporal y geogrÃ¡fico automÃ¡tico
"""

import re
import logging
from typing import List, Dict, Any, Optional
from datetime import datetime

logger = logging.getLogger(__name__)

class IntelligentKeywordGenerator:
    """ðŸŽ¯ Generador inteligente de keywords y tÃ©rminos de bÃºsqueda"""
    
    def __init__(self):
        # Entidades importantes que SIEMPRE deben preservarse
        self.preserve_entities = {
            'personas': ['milei', 'javier', 'biden', 'musk', 'elon', 'trump', 'cristina', 'massa', 
                        'alberto', 'fernÃ¡ndez', 'macri', 'mauricio', 'cristiano', 'messi', 'lionel'],
            'lugares': ['argentina', 'buenos', 'aires', 'cÃ³rdoba', 'mendoza', 'espaÃ±a', 'madrid', 
                       'barcelona', 'valencia', 'mÃ©xico', 'colombia', 'chile', 'usa', 'eeuu'],
            'organizaciones': ['fifa', 'onu', 'oea', 'mercosur', 'gobierno', 'congress', 'senate'],
            'tecnologia': ['inteligencia', 'artificial', 'blockchain', 'bitcoin', 'crypto', 'tesla', 
                          'apple', 'google', 'microsoft', 'meta', 'openai', 'chatgpt'],
            'conceptos': ['economÃ­a', 'polÃ­tica', 'inflaciÃ³n', 'dÃ³lar', 'peso', 'elecciones', 
                         'democracia', 'libertad', 'socialismo', 'capitalismo', 'crisis'],
            'temporal': ['2024', '2025', 'enero', 'febrero', 'marzo', 'abril', 'mayo', 'junio',
                        'actual', 'reciente', 'nuevo', 'Ãºltima', 'Ãºltimo'],
            'musica': ['arctic', 'monkeys', 'banda', 'mÃºsica', 'rock', 'discografÃ­a', 'Ã¡lbum', 
                      'canciÃ³n', 'concierto', 'gira', 'festival'],
            'anime_manga': ['attack', 'titan', 'shingeki', 'kyojin', 'eren', 'mikasa', 'armin', 'levi', 
                           'anime', 'manga', 'naruto', 'one', 'piece', 'dragon', 'ball', 'studio', 
                           'ghibli', 'miyazaki', 'otaku', 'cosplay'],
            'entretenimiento': ['netflix', 'disney', 'marvel', 'dc', 'comics', 'superhero', 'movie', 
                               'film', 'serie', 'temporada', 'episodio', 'actor', 'actress', 'director']
        }
        
        # Palabras meta que deben eliminarse COMPLETAMENTE
        self.meta_words = {
            'instrucciones': ['buscar', 'informaciÃ³n', 'sobre', 'acerca', 'utilizar', 'herramienta', 
                             'web_search', 'realizar', 'generar', 'crear', 'obtener', 'necesario',
                             'completar', 'especÃ­fico', 'datos', 'anÃ¡lisis', 'informe', 'recopilar',
                             'desarrollar', 'estrategia', 'bÃºsqueda', 'actual', 'actuales', 'web'],
            'conectores': ['para', 'con', 'por', 'desde', 'hasta', 'durante', 'mediante', 'segÃºn',
                          'ante', 'bajo', 'contra', 'entre', 'hacia', 'segÃºn', 'sin', 'tras'],
            'articulos': ['el', 'la', 'los', 'las', 'un', 'una', 'unos', 'unas'],
            'pronombres': ['que', 'cual', 'quien', 'donde', 'cuando', 'como', 'este', 'esta', 'ese', 'esa']
        }
        
        # Patrones problemÃ¡ticos que indican queries mal formados
        self.problematic_patterns = [
            r'\brealiza\s+informe\b',
            r'\butilizar\s+herramienta\b', 
            r'\bweb_search\s+para\b',
            r'\binformaciÃ³n\s+especÃ­fica\s+sobre\b',
            r'\bgenera\s+(un|una)\s+(anÃ¡lisis|informe|reporte)\b',
            r'\brecopilar\s+datos\s+de\s+mercado\b',
            r'\brealizar\s+una\s+bÃºsqueda\s+web\b',
            r'\bdesarrollar\s+una\s+estrategia\b',
            r'\bobtener\s+datos\s+actuales\b'
        ]
    
    def get_intelligent_keywords(self, query_text: str) -> str:
        """ðŸŽ¯ FUNCIÃ“N PRINCIPAL: Generar keywords inteligentes"""
        
        if not query_text or len(query_text.strip()) < 3:
            return "informaciÃ³n actualizada"
        
        print(f"ðŸ§  INTELLIGENT GENERATOR INPUT: '{query_text}'")
        
        # 1. Detectar si es query problemÃ¡tico
        if self._is_problematic_query(query_text):
            print("âš ï¸ PROBLEMATIC QUERY detectado - aplicando correcciÃ³n especial")
            return self._fix_problematic_query(query_text)
        
        # 2. Extraer entidades importantes (nombres propios, conceptos clave)
        entities = self._extract_important_entities(query_text)
        
        # 3. Extraer conceptos principales 
        concepts = self._extract_main_concepts(query_text)
        
        # 4. Combinar y optimizar
        result = self._combine_and_optimize(entities, concepts, query_text)
        
        print(f"âœ… INTELLIGENT RESULT: '{query_text}' â†’ '{result}'")
        return result
    
    def get_multiple_search_variants(self, query_text: str, count: int = 3) -> List[str]:
        """ðŸ”„ Generar mÃºltiples variantes de bÃºsqueda para diversidad"""
        
        base_keywords = self.get_intelligent_keywords(query_text)
        variants = [base_keywords]
        
        # Variante 1: Con contexto temporal
        if '2025' not in base_keywords and '2024' not in base_keywords:
            variants.append(f"{base_keywords} 2025 actualidad")
        
        # Variante 2: Con especificidad geogrÃ¡fica si aplicable
        if any(lugar in query_text.lower() for lugar in self.preserve_entities['lugares']):
            variants.append(f"{base_keywords} noticias recientes")
        else:
            variants.append(f"{base_keywords} informaciÃ³n completa")
        
        # Variante 3: Con enfoque especÃ­fico
        if any(persona in query_text.lower() for persona in self.preserve_entities['personas']):
            variants.append(f"{base_keywords} biografÃ­a trayectoria")
        elif any(tech in query_text.lower() for tech in self.preserve_entities['tecnologia']):
            variants.append(f"{base_keywords} definiciÃ³n caracterÃ­sticas")
        else:
            variants.append(f"{base_keywords} guÃ­a completa")
        
        return variants[:count]
    
    def _is_problematic_query(self, query_text: str) -> bool:
        """ðŸš¨ Detectar queries problemÃ¡ticos que generan keywords inÃºtiles"""
        
        query_lower = query_text.lower()
        
        # ðŸŽ¯ FIRST CHECK: Si contiene temas especÃ­ficos conocidos, NUNCA es problemÃ¡tico
        specific_topics = [
            'attack on titan', 'shingeki no kyojin', 'eren jaeger', 'mikasa ackerman',
            'arctic monkeys', 'alex turner', 'the strokes', 'coldplay',
            'inteligencia artificial', 'machine learning', 'chatgpt', 'openai',
            'javier milei', 'argentina presidente', 'elecciones argentina',
            'netflix series', 'disney plus', 'marvel movies', 'dc comics',
            'bitcoin price', 'cryptocurrency', 'blockchain technology',
            'climate change', 'global warming', 'renewable energy'
        ]
        
        for topic in specific_topics:
            if topic in query_lower:
                print(f"âœ… SPECIFIC TOPIC DETECTED: '{topic}' - NOT problematic")
                return False
        
        # ðŸŽ¯ SECOND CHECK: Si tiene nombres propios claros, probablemente no es problemÃ¡tico
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', query_text)
        if len(proper_nouns) >= 2:  # Dos o mÃ¡s nombres propios = tema especÃ­fico
            print(f"âœ… PROPER NOUNS DETECTED: {proper_nouns} - NOT problematic")
            return False
        
        # Verificar patrones problemÃ¡ticos conocidos
        for pattern in self.problematic_patterns:
            if re.search(pattern, query_lower):
                return True
        
        # Verificar si tiene muchas palabras meta vs. pocas entidades
        meta_count = sum(1 for category in self.meta_words.values() 
                        for word in category if word in query_lower)
        
        entity_count = sum(1 for category in self.preserve_entities.values()
                          for entity in category if entity in query_lower)
        
        # ðŸŽ¯ AJUSTE CRÃTICO: Solo es problemÃ¡tico si hay MUCHAS mÃ¡s palabras meta que entidades
        # Y no contiene temas especÃ­ficos obvios
        if meta_count > 5 and entity_count < 1:
            # DOUBLE CHECK: Buscar entidades que no estÃ©n en la lista pero que sean obvias
            potential_entities = re.findall(r'\b[a-zA-Z]{4,}\b', query_text)
            non_meta_entities = []
            
            for word in potential_entities:
                word_lower = word.lower()
                if not any(word_lower in metas for metas in self.meta_words.values()):
                    non_meta_entities.append(word_lower)
            
            # Si hay entidades potenciales no-meta, NO es problemÃ¡tico
            if len(non_meta_entities) >= 2:
                print(f"âœ… POTENTIAL ENTITIES FOUND: {non_meta_entities} - NOT problematic")
                return False
                
            return True
        
        return False
    
    def _fix_problematic_query(self, query_text: str) -> str:
        """ðŸ”§ Reparar queries problemÃ¡ticos extrayendo el tema real"""
        
        query_lower = query_text.lower()
        
        # Buscar patrones especÃ­ficos de tema
        theme_patterns = [
            r'sobre\s+"([^"]+)"',  # sobre "tema"
            r'sobre\s+([a-zÃ¡Ã©Ã­Ã³ÃºÃ±\s]+?)(?:\s+en\s|\s+con\s|$)',  # sobre tema
            r'informaciÃ³n.*?([a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,}(?:\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,})*)',  # informaciÃ³n tema
            r'anÃ¡lisis.*?([a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,}(?:\s+[a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{4,})*)',  # anÃ¡lisis tema
            r'mercado\s+objetivo.*?(redes\s+sociales|social\s+media|marketing)',  # mercado + marketing
            r'tendencias\s+de\s+(redes\s+sociales|social\s+media|marketing)',  # tendencias marketing
            r'estrategia\s+de\s+(marketing|redes\s+sociales|social\s+media)',  # estrategia marketing
            r'comportamiento\s+de\s+la\s+audiencia',  # comportamiento audiencia
        ]
        
        for pattern in theme_patterns:
            match = re.search(pattern, query_text, re.IGNORECASE)
            if match:
                theme = match.group(1).strip()
                print(f"ðŸ”§ TEMA EXTRAÃDO DE QUERY PROBLEMÃTICO: '{theme}'")
                return self._clean_and_enhance_theme(theme)
        
        # Buscar conceptos especÃ­ficos del contexto de marketing
        marketing_concepts = ['marketing', 'redes sociales', 'social media', 'audiencia', 
                             'mercado', 'tendencias', 'comportamiento', 'digital', 'contenido']
        
        found_concepts = []
        for concept in marketing_concepts:
            if concept in query_lower:
                found_concepts.append(concept)
        
        if found_concepts:
            result = ' '.join(found_concepts[:3]) + ' 2025'
            print(f"ðŸ”§ CONCEPTOS MARKETING EXTRAÃDOS: '{result}'")
            return result
        
        # Si no se encuentra patrÃ³n, usar extracciÃ³n de entidades de emergencia
        words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±A-ZÃÃ‰ÃÃ“ÃšÃ‘]{4,}\b', query_text)
        significant_words = []
        
        for word in words:
            word_lower = word.lower()
            # Incluir si es entidad importante o no es palabra meta
            if (any(word_lower in entities for entities in self.preserve_entities.values()) or
                not any(word_lower in metas for metas in self.meta_words.values())):
                significant_words.append(word_lower)
        
        if significant_words:
            result = ' '.join(significant_words[:4])
            print(f"ðŸ”§ EMERGENCIA - Palabras significativas extraÃ­das: '{result}'")
            return result
        
        # Ãšltimo recurso
        return "marketing digital redes sociales 2025"
    
    def _clean_and_enhance_theme(self, theme: str) -> str:
        """âœ¨ Limpiar y mejorar tema extraÃ­do"""
        
        # Remover comillas y espacios extra
        clean_theme = re.sub(r'["\']', '', theme).strip()
        
        # Si el tema es muy corto, agregarlo contexto relevante
        if len(clean_theme.split()) < 2:
            if any(keyword in clean_theme.lower() for keyword in ['marketing', 'social', 'redes']):
                return f"{clean_theme} estrategias marketing digital 2025"
            elif 'inteligencia' in clean_theme.lower():
                return f"{clean_theme} tendencias aplicaciones 2025"
            else:
                return f"{clean_theme} informaciÃ³n completa actualizada 2025"
        
        # Si ya es un buen tema, agregar contexto temporal
        if '2024' not in clean_theme and '2025' not in clean_theme:
            return f"{clean_theme} 2025"
        
        return clean_theme
    
    def _extract_important_entities(self, query_text: str) -> List[str]:
        """ðŸ·ï¸ Extraer entidades importantes (nombres propios, conceptos clave) - CORREGIDO FILTRADO META"""
        
        entities = []
        query_lower = query_text.lower()
        
        # ðŸ”¥ FILTRO CRÃTICO: Lista completa de palabras meta que nunca deben ser entidades
        meta_filter_entities = {
            'investigar', 'informaciÃ³n', 'especÃ­fica', 'buscar', 'datos', 'sobre', 'acerca',
            'realizar', 'generar', 'crear', 'anÃ¡lisis', 'informe', 'completo', 'completa',
            'recopilar', 'obtener', 'utilizar', 'herramienta', 'web', 'search', 'incluyendo',
            'mediante', 'para', 'con', 'del', 'las', 'los', 'una', 'actualizada', 'actuales',
            'relevante', 'relevantes', 'importante', 'importantes', 'necesario', 'necesaria',
            'completar', 'desarrollo', 'especÃ­ficos', 'general', 'generales'
        }
        
        # Buscar todas las entidades de alta prioridad (filtradas)
        for category, entity_list in self.preserve_entities.items():
            for entity in entity_list:
                if entity in query_lower and entity not in meta_filter_entities:
                    entities.append(entity)
        
        # Buscar nombres propios adicionales (Capitalizados) y filtrar meta words
        proper_nouns = re.findall(r'\b[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]{2,}(?:\s+[A-ZÃÃ‰ÃÃ“ÃšÃ‘][a-zÃ¡Ã©Ã­Ã³ÃºÃ±]+)*\b', query_text)
        for noun in proper_nouns:
            noun_lower = noun.lower()
            if (len(noun) > 3 and 
                noun_lower not in meta_filter_entities and
                not any(meta in noun_lower for meta in ['investig', 'informac', 'buscar', 'datos'])):
                entities.append(noun_lower)
        
        # Remover duplicados manteniendo orden
        seen = set()
        unique_entities = []
        for entity in entities:
            if entity not in seen:
                seen.add(entity)
                unique_entities.append(entity)
        
        return unique_entities[:6]  # MÃ¡ximo 6 entidades mÃ¡s importantes
    
    def _extract_main_concepts(self, query_text: str) -> List[str]:
        """ðŸ’¡ Extraer conceptos principales del texto - CORREGIDO PARA FILTRAR MEJOR"""
        
        concepts = []
        
        # ðŸ”¥ LISTA AMPLIADA DE PALABRAS META QUE NUNCA DEBEN INCLUIRSE
        extended_meta_filter = {
            'investigar', 'informaciÃ³n', 'especÃ­fica', 'buscar', 'datos', 'sobre', 'acerca',
            'realizar', 'generar', 'crear', 'anÃ¡lisis', 'informe', 'completo', 'completa',
            'recopilar', 'obtener', 'utilizar', 'herramienta', 'web', 'search', 'incluyendo',
            'mediante', 'para', 'con', 'del', 'las', 'los', 'una', 'actualizada', 'actuales',
            'relevante', 'relevantes', 'importante', 'importantes', 'necesario', 'necesaria',
            'completar', 'desarrollo', 'especÃ­ficos', 'general', 'generales', 'relacionados',
            'relacionadas', 'particular', 'particulares', 'diversos', 'diversas'
        }
        
        # Extraer palabras significativas (4+ caracteres)
        words = re.findall(r'\b[a-zÃ¡Ã©Ã­Ã³ÃºÃ±A-ZÃÃ‰ÃÃ“ÃšÃ‘]{4,}\b', query_text)
        
        for word in words:
            word_lower = word.lower()
            
            # DOBLE FILTRO: palabras meta del objeto + lista extendida
            is_meta_original = any(word_lower in meta_category for meta_category in self.meta_words.values())
            is_meta_extended = word_lower in extended_meta_filter
            
            # Solo incluir si NO es palabra meta en ninguna de las listas
            if not is_meta_original and not is_meta_extended and len(word_lower) >= 4:
                concepts.append(word_lower)
        
        return concepts[:8]  # MÃ¡ximo 8 conceptos
    
    def _combine_and_optimize(self, entities: List[str], concepts: List[str], original_query: str) -> str:
        """âš¡ Combinar y optimizar entidades y conceptos - CORREGIDO PARA FILTRAR PALABRAS META"""
        
        # ðŸ”¥ FILTRO CRÃTICO: Remover palabras meta de TODAS las listas
        meta_filter = {
            'investigar', 'informaciÃ³n', 'especÃ­fica', 'buscar', 'datos', 'sobre', 'acerca',
            'realizar', 'generar', 'crear', 'anÃ¡lisis', 'informe', 'completo', 'completa',
            'recopilar', 'obtener', 'utilizar', 'herramienta', 'web', 'search', 'incluyendo',
            'mediante', 'para', 'con', 'del', 'las', 'los', 'una', 'actualizada', 'actuales',
            'relevante', 'relevantes', 'importante', 'importantes', 'necesario', 'necesaria'
        }
        
        # 1. FILTRAR ENTIDADES - Remover palabras meta
        filtered_entities = []
        for entity in entities:
            if entity.lower() not in meta_filter and len(entity) >= 3:
                filtered_entities.append(entity)
        
        # 2. FILTRAR CONCEPTOS - Remover palabras meta  
        filtered_concepts = []
        for concept in concepts:
            if concept.lower() not in meta_filter and len(concept) >= 3:
                filtered_concepts.append(concept)
        
        # 3. Priorizar entidades limpias (son mÃ¡s importantes)
        important_terms = filtered_entities[:4]  # Top 4 entidades sin meta words
        
        # 4. Agregar conceptos limpios que no sean repetitivos
        for concept in filtered_concepts:
            if (concept not in important_terms and 
                len(important_terms) < 5 and
                not any(concept in term for term in important_terms)):  # Evitar redundancia
                important_terms.append(concept)
        
        # 5. Si aÃºn muy pocos tÃ©rminos despuÃ©s del filtrado, agregar contexto especÃ­fico
        if len(important_terms) < 2:
            # Buscar tÃ©rminos especÃ­ficos que NO sean meta
            query_lower = original_query.lower()
            
            # Para anime/manga
            if any(term in query_lower for term in ['attack on titan', 'shingeki', 'anime', 'manga']):
                if 'attack' not in important_terms and 'titan' not in important_terms:
                    important_terms.extend(['attack', 'titan'])
                important_terms.append('anime')
            # Para mÃºsica
            elif any(term in query_lower for term in ['arctic monkeys', 'banda', 'mÃºsica', 'discografÃ­a']):
                important_terms.append('mÃºsica')
                important_terms.append('banda')
            # Para personas
            elif any(persona in query_lower for persona in self.preserve_entities['personas']):
                important_terms.append('biografÃ­a')
            # Para tecnologÃ­a  
            elif any(tech in query_lower for tech in self.preserve_entities['tecnologia']):
                important_terms.append('tecnologÃ­a')
            # Fallback genÃ©rico
            else:
                important_terms.append('noticias')
        
        # 6. Construir resultado final SIN palabras meta
        result = ' '.join(important_terms[:5])  # MÃ¡ximo 5 tÃ©rminos
        
        # 7. VALIDACIÃ“N FINAL: Si el resultado contiene palabras meta, limpiar
        for meta_word in meta_filter:
            result = result.replace(meta_word, '').strip()
        
        # Limpiar espacios mÃºltiples
        result = ' '.join(result.split())
        
        # 8. Si el resultado es muy corto despuÃ©s de la limpieza, agregar contexto
        if len(result.split()) < 2:
            if any(term in original_query.lower() for term in ['attack on titan', 'titan']):
                result = 'attack titan anime manga'
            elif any(term in original_query.lower() for term in ['arctic monkeys']):
                result = 'arctic monkeys mÃºsica banda'
            else:
                result += ' noticias actualidad'
        
        # 9. Agregar aÃ±o solo si es muy corto y no tiene contexto temporal
        if ('2024' not in result and '2025' not in result and len(result.split()) < 3):
            result += ' 2025'
        
        return result.strip()

    def detect_granular_search_needs(self, query_text: str) -> List[Dict[str, str]]:
        """
        ðŸŽ¯ DETECTOR GENÃ‰RICO INTELIGENTE DE BÃšSQUEDAS GRANULARES
        
        Analiza CUALQUIER consulta y determina automÃ¡ticamente si necesita
        mÃºltiples bÃºsquedas especÃ­ficas, SIN hardcodear temas especÃ­ficos
        """
        query_lower = query_text.lower()
        searches = []
        
        print(f"ðŸ” ANALYZING QUERY FOR GRANULAR NEEDS: '{query_text}'")
        
        # ðŸŽ¯ STEP 1: DETECTAR SI LA CONSULTA SOLICITA INFORMACIÃ“N AMPLIA/COMPLETA
        comprehensive_indicators = [
            'informaciÃ³n completa', 'datos completos', 'informaciÃ³n sobre',
            'investigar sobre', 'buscar informaciÃ³n', 'anÃ¡lisis completo',
            'estudiar', 'recopilar informaciÃ³n', 'informaciÃ³n relevante',
            'aspectos importantes', 'caracterÃ­sticas principales',
            'investigar datos sobre', 'buscar datos sobre', 'anÃ¡lisis de',
            'investigaciÃ³n sobre', 'estudio sobre', 'datos sobre',
            'informaciÃ³n especÃ­fica sobre', 'investigar informaciÃ³n sobre',
            'incluyendo', 'que incluya', 'abarcando', 'cubriendo',
            'informaciÃ³n detallada', 'datos detallados', 'anÃ¡lisis detallado',
            'informe sobre', 'reporte sobre', 'investigar', 'buscar datos'
        ]
        
        is_comprehensive_request = any(indicator in query_lower for indicator in comprehensive_indicators)
        
        if not is_comprehensive_request:
            print("âŒ No es solicitud comprehensiva - bÃºsqueda simple")
            return []
        
        # ðŸŽ¯ STEP 2: EXTRAER EL TEMA/SUJETO PRINCIPAL
        main_subject = self._extract_main_subject_generic(query_text)
        
        if not main_subject:
            print("âŒ No se pudo extraer tema principal")
            return []
            
        print(f"âœ… TEMA PRINCIPAL DETECTADO: '{main_subject}'")
        
        # ðŸŽ¯ STEP 3: DETECTAR ASPECTOS ESPECÃFICOS MENCIONADOS
        mentioned_aspects = self._extract_mentioned_aspects(query_text)
        print(f"ðŸŽ¯ ASPECTOS MENCIONADOS: {mentioned_aspects}")
        
        # ðŸŽ¯ STEP 4: GENERAR BÃšSQUEDAS GRANULARES BASADAS EN TIPO DE TEMA
        subject_type = self._classify_subject_type_generic(main_subject, query_text)
        print(f"ðŸ“Š TIPO DE TEMA CLASIFICADO: {subject_type}")
        
        searches = self._generate_searches_by_type_generic(main_subject, subject_type, mentioned_aspects)
        
        print(f"âœ… BÃšSQUEDAS GRANULARES GENERADAS: {len(searches)}")
        for search in searches:
            print(f"   ðŸŽ¯ {search['category']}: {search['query']}")
        
        return searches if len(searches) > 1 else []
    
    def _extract_main_subject_generic(self, query_text: str) -> str:
        """ðŸŽ¯ Extraer el tema/sujeto principal de CUALQUIER consulta - VERSIÃ“N CORREGIDA"""
        import re
        
        print(f"ðŸ” EXTRACTING SUBJECT FROM: '{query_text}'")
        
        # ðŸŽ¯ MÃ‰TODO ESPECIAL: Detectar nombres compuestos especÃ­ficos conocidos PRIMERO
        known_subjects = [
            r'\battack\s+on\s+titan\b',
            r'\bshingeki\s+no\s+kyojin\b', 
            r'\barctic\s+monkeys\b',
            r'\bcoldplay\b',
            r'\bthe\s+strokes\b',
            r'\binteligencia\s+artificial\b',
            r'\bmachine\s+learning\b',
            r'\bjavier\s+milei\b',
            r'\bcambio\s+climÃ¡tico\b',
            r'\bcalentamiento\s+global\b'
        ]
        
        for subject_pattern in known_subjects:
            match = re.search(subject_pattern, query_text, re.IGNORECASE)
            if match:
                subject = match.group(0)
                print(f"âœ… SUBJECT FOUND (Method 0 - Known Subjects): '{subject}'")
                return subject.title()
        
        # MÃ‰TODO 1: Buscar tÃ©rminos especÃ­ficos despuÃ©s de palabras clave (MÃS PRECISO)
        subject_patterns = [
            # Patrones con delimitadores claros
            r'sobre\s+"([^"]+)"',  # sobre "tema exacto"
            r'sobre\s+([a-zA-Z][a-zA-Z\s]+?)\s*(?:\s+incluyendo|\s+con|\s+-|\s+y\s|\s+para|\.|$)',  # sobre tema ANTES de "incluyendo"
            r'informaciÃ³n\s+(?:completa\s+|especÃ­fica\s+)?sobre\s+([a-zA-Z][a-zA-Z\s]+?)\s*(?:\s+incluyendo|\s+con|\s+-|\s+y\s|\s+para|\.|$)',
            r'datos\s+(?:completos\s+)?sobre\s+([a-zA-Z][a-zA-Z\s]+?)\s*(?:\s+incluyendo|\s+con|\s+-|\s+y\s|\s+para|\.|$)',
            r'investigar\s+(?:informaciÃ³n\s+(?:especÃ­fica\s+)?sobre\s+)?([a-zA-Z][a-zA-Z\s]+?)\s*(?:\s+incluyendo|\s+con|\s+-|\s+y\s|\s+para|\.|$)',
            r'buscar\s+informaciÃ³n\s+(?:completa\s+|especÃ­fica\s+)?sobre\s+([a-zA-Z][a-zA-Z\s]+?)\s*(?:\s+incluyendo|\s+con|\s+-|\s+y\s|\s+para|\.|$)'
        ]
        
        for pattern in subject_patterns:
            match = re.search(pattern, query_text, re.IGNORECASE)
            if match:
                subject = match.group(1).strip()
                subject = re.sub(r'\s+', ' ', subject)  # Limpiar espacios mÃºltiples
                
                # Validar que no sean palabras meta y que sea razonable
                meta_words = ['informaciÃ³n', 'datos', 'sobre', 'anÃ¡lisis', 'buscar', 'completa', 'completar', 'especÃ­fica']
                if (len(subject) > 3 and 
                    not any(meta.lower() in subject.lower() for meta in meta_words) and
                    not subject.lower() in ['y', 'el', 'la', 'los', 'las', 'de', 'del', 'con'] and
                    len(subject.split()) <= 4):  # No mÃ¡s de 4 palabras
                    print(f"âœ… SUBJECT FOUND (Method 1): '{subject}'")
                    return subject
        
        # MÃ‰TODO 2: Buscar nombres propios (2+ palabras capitalizadas)
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)+\b', query_text)
        for noun in proper_nouns:
            if len(noun.split()) >= 2 and len(noun.split()) <= 3:  # Entre 2 y 3 palabras
                print(f"âœ… SUBJECT FOUND (Method 2 - Proper Nouns): '{noun}'")
                return noun
        
        # MÃ‰TODO 3: Buscar tÃ©rminos compuestos comunes (sin capitalizaciÃ³n)
        # TÃ©rminos compuestos importantes conocidos
        known_compounds = [
            r'\bcambio\s+climÃ¡tico\b',
            r'\bcalentamiento\s+global\b',
            r'\binteligencia\s+artificial\b',
            r'\bmachine\s+learning\b',
            r'\baprendizaje\s+automÃ¡tico\b',
            r'\beconomÃ­a\s+argentina\b',
            r'\beconomÃ­a\s+mundial\b',
            r'\bcriptomonedas\b',
            r'\benergÃ­a\s+renovable\b',
            r'\bmedio\s+ambiente\b',
            r'\brecursos\s+naturales\b',
            r'\bdesarrollo\s+sostenible\b'
        ]
        
        for compound_pattern in known_compounds:
            match = re.search(compound_pattern, query_text, re.IGNORECASE)
            if match:
                subject = match.group(0)
                print(f"âœ… SUBJECT FOUND (Method 3 - Known Compounds): '{subject}'")
                return subject.title()
        
        # MÃ‰TODO 4: Buscar cualquier tÃ©rmino compuesto de 2+ palabras ANTES DE "incluyendo"
        compound_before_including = re.search(r'\b([a-zA-Z]{3,}\s+[a-zA-Z]{3,}(?:\s+[a-zA-Z]{3,})?)\s+incluyendo\b', query_text, re.IGNORECASE)
        if compound_before_including:
            subject = compound_before_including.group(1).strip()
            meta_phrases = {'informaciÃ³n sobre', 'datos sobre', 'buscar informaciÃ³n', 'investigar sobre'}
            if subject.lower() not in meta_phrases and len(subject) > 8:
                print(f"âœ… SUBJECT FOUND (Method 4 - Before Including): '{subject}'")
                return subject.title()
        
        # MÃ‰TODO 5: Buscar nombres propios simples importantes
        single_nouns = re.findall(r'\b[A-Z][a-z]{4,}\b', query_text)
        skip_words = {'Investigar', 'Buscar', 'Datos', 'InformaciÃ³n', 'AnÃ¡lisis', 'Sobre', 'Para', 'Con', 'Realizar', 'Incluyendo'}
        
        for noun in single_nouns:
            if noun not in skip_words:
                print(f"âœ… SUBJECT FOUND (Method 5 - Single Proper Noun): '{noun}'")
                return noun
        
        print("âŒ NO SUBJECT EXTRACTED")
        return None
    
    def _extract_mentioned_aspects(self, query_text: str) -> List[str]:
        """ðŸ” Extraer aspectos especÃ­ficos mencionados en la consulta"""
        query_lower = query_text.lower()
        aspects = []
        
        # Mapeo de palabras clave a aspectos
        aspect_keywords = {
            'trama': ['trama', 'historia', 'argumento', 'narrativa', 'plot'],
            'personajes': ['personajes', 'protagonistas', 'caracteres', 'characters'],
            'biografÃ­a': ['biografÃ­a', 'vida', 'personal', 'nacimiento', 'historia personal'],
            'historia': ['historia', 'orÃ­genes', 'desarrollo', 'evoluciÃ³n', 'pasado'],
            'contexto': ['contexto', 'ambiente', 'Ã©poca', 'perÃ­odo', 'marco'],
            'crÃ­tica': ['crÃ­tica', 'recepciÃ³n', 'opiniones', 'reseÃ±as', 'evaluaciÃ³n'],
            'impacto': ['impacto', 'influencia', 'legado', 'consecuencias', 'efectos'],
            'caracterÃ­sticas': ['caracterÃ­sticas', 'propiedades', 'atributos', 'rasgos'],
            'causas': ['causas', 'orÃ­genes', 'razones', 'motivos'],
            'efectos': ['efectos', 'consecuencias', 'resultados', 'impactos'],
            'soluciones': ['soluciones', 'remedios', 'propuestas', 'alternativas'],
            'obras': ['obras', 'trabajos', 'creaciones', 'producciÃ³n'],
            'carrera': ['carrera', 'trayectoria', 'profesional', 'trabajo'],
            'polÃ­tica': ['polÃ­tica', 'posiciones', 'ideologÃ­a', 'propuestas']
        }
        
        for aspect, keywords in aspect_keywords.items():
            if any(keyword in query_lower for keyword in keywords):
                aspects.append(aspect)
        
        return aspects
    
    def _classify_subject_type_generic(self, subject: str, query_text: str) -> str:
        """ðŸ“Š Clasificar genÃ©ricamente el tipo de tema basado en indicadores"""
        subject_lower = subject.lower()
        query_lower = query_text.lower()
        
        # Indicadores de tipo de tema
        if (any(indicator in query_lower for indicator in ['anime', 'manga', 'serie', 'pelÃ­cula', 'film']) or
            any(name in subject_lower for name in ['attack on titan', 'shingeki', 'naruto', 'one piece', 'dragon ball'])):
            return 'entertainment'
        elif any(indicator in query_lower for indicator in ['banda', 'mÃºsica', 'cantante', 'artista musical']):
            return 'music'  
        elif any(indicator in query_lower for indicator in ['presidente', 'polÃ­tico', 'lÃ­der', 'personalidad']):
            return 'person'
        elif any(indicator in query_lower for indicator in ['tecnologÃ­a', 'ciencia', 'cientÃ­fico', 'tÃ©cnico']):
            return 'technology'
        elif any(indicator in query_lower for indicator in ['economÃ­a', 'econÃ³mico', 'mercado', 'financiero']):
            return 'economics'
        elif any(indicator in query_lower for indicator in ['equipo', 'deporte', 'fÃºtbol', 'selecciÃ³n']):
            return 'sports'
        elif any(indicator in query_lower for indicator in ['libro', 'novela', 'autor', 'literatura']):
            return 'literature'
        elif any(indicator in query_lower for indicator in ['pintor', 'artista', 'arte', 'pintura']):
            return 'art'
        elif any(indicator in query_lower for indicator in ['histÃ³rico', 'historia', 'Ã©poca', 'perÃ­odo']):
            return 'history'
        elif any(indicator in query_lower for indicator in ['empresa', 'compaÃ±Ã­a', 'corporaciÃ³n', 'negocio']):
            return 'business'
        else:
            # ClasificaciÃ³n por nombres propios conocidos o contexto
            if len(subject.split()) >= 2:  # Nombres compuestos = probablemente persona o obra
                return 'person_or_work'
            else:
                return 'general_topic'
    
    def _generate_searches_by_type_generic(self, subject: str, subject_type: str, mentioned_aspects: List[str]) -> List[Dict[str, str]]:
        """ðŸŽ¯ Generar bÃºsquedas especÃ­ficas basadas en el tipo de tema"""
        searches = []
        
        # Plantillas por tipo de tema
        search_templates = {
            'entertainment': [
                ('trama', f'{subject} trama historia argumento resumen'),
                ('personajes', f'{subject} personajes principales protagonistas reparto'),
                ('crÃ­tica', f'{subject} crÃ­ticas reseÃ±as puntuaciÃ³n recepciÃ³n'),
                ('contexto', f'{subject} contexto producciÃ³n trasfondo'),
                ('impacto', f'{subject} impacto cultural legado influencia')
            ],
            'music': [
                ('historia', f'{subject} historia formaciÃ³n miembros banda'),
                ('discografÃ­a', f'{subject} discografÃ­a Ã¡lbumes canciones hits'),
                ('estilo', f'{subject} estilo musical gÃ©nero evoluciÃ³n'),
                ('logros', f'{subject} premios reconocimientos logros'),
                ('actualidad', f'{subject} noticias recientes conciertos giras')
            ],
            'person': [
                ('biografÃ­a', f'{subject} biografÃ­a vida personal historia'),
                ('carrera', f'{subject} carrera trayectoria profesional'),
                ('logros', f'{subject} logros reconocimientos premios'),
                ('posiciones', f'{subject} posiciones ideologÃ­a propuestas'),
                ('actualidad', f'{subject} noticias recientes declaraciones 2025')
            ],
            'technology': [
                ('definiciÃ³n', f'{subject} definiciÃ³n conceptos bÃ¡sicos explicaciÃ³n'),
                ('aplicaciones', f'{subject} aplicaciones usos prÃ¡cticos ejemplos'),
                ('ventajas', f'{subject} ventajas beneficios impacto positivo'),
                ('desafÃ­os', f'{subject} desventajas riesgos limitaciones'),
                ('futuro', f'{subject} tendencias futuro 2025 innovaciones')
            ],
            'economics': [
                ('situaciÃ³n', f'{subject} situaciÃ³n actual estado 2025'),
                ('causas', f'{subject} causas factores antecedentes'),
                ('efectos', f'{subject} efectos consecuencias impacto'),
                ('polÃ­ticas', f'{subject} polÃ­ticas medidas propuestas'),
                ('perspectivas', f'{subject} perspectivas futuro pronÃ³sticos')
            ],
            'literature': [
                ('trama', f'{subject} trama resumen argumento historia'),
                ('personajes', f'{subject} personajes principales protagonistas'),
                ('anÃ¡lisis', f'{subject} anÃ¡lisis literario temas sÃ­mbolos'),
                ('contexto', f'{subject} contexto histÃ³rico Ã©poca ambientaciÃ³n'),
                ('crÃ­tica', f'{subject} crÃ­tica literaria recepciÃ³n reseÃ±as')
            ],
            'art': [
                ('biografÃ­a', f'{subject} biografÃ­a vida personal historia'),
                ('obras', f'{subject} obras principales trabajos destacados'),
                ('estilo', f'{subject} estilo artÃ­stico tÃ©cnica caracterÃ­sticas'),
                ('contexto', f'{subject} contexto histÃ³rico Ã©poca artÃ­stica'),
                ('legado', f'{subject} legado influencia impacto arte')
            ],
            'person_or_work': [
                ('informaciÃ³n', f'{subject} informaciÃ³n general datos bÃ¡sicos'),
                ('historia', f'{subject} historia orÃ­genes desarrollo'),
                ('caracterÃ­sticas', f'{subject} caracterÃ­sticas principales aspectos'),
                ('impacto', f'{subject} importancia relevancia significado'),
                ('actualidad', f'{subject} situaciÃ³n actual noticias recientes')
            ],
            'general_topic': [
                ('definiciÃ³n', f'{subject} definiciÃ³n quÃ© es conceptos'),
                ('aspectos', f'{subject} aspectos principales caracterÃ­sticas'),
                ('importancia', f'{subject} importancia relevancia significado'),
                ('contexto', f'{subject} contexto situaciÃ³n actual'),
                ('perspectivas', f'{subject} anÃ¡lisis opiniones perspectivas')
            ]
        }
        
        # Usar plantilla por defecto si no se encuentra el tipo
        templates = search_templates.get(subject_type, search_templates['general_topic'])
        
        # Generar bÃºsquedas
        for category, query in templates:
            searches.append({
                'query': query,
                'category': category
            })
        
        return searches

# Funciones pÃºblicas para usar desde unified_web_search_tool.py
def get_intelligent_keywords(query_text: str) -> str:
    """ðŸŽ¯ FunciÃ³n principal para generar keywords inteligentes"""
    generator = IntelligentKeywordGenerator()
    return generator.get_intelligent_keywords(query_text)

def get_multiple_search_variants(query_text: str, count: int = 3) -> List[str]:
    """ðŸ”„ Generar mÃºltiples variantes de bÃºsqueda para diversidad"""
    generator = IntelligentKeywordGenerator()
    return generator.get_multiple_search_variants(query_text, count)

def detect_granular_search_needs(query_text: str) -> List[Dict[str, str]]:
    """ðŸŽ¯ Detectar si una consulta necesita bÃºsquedas granulares mÃºltiples"""
    generator = IntelligentKeywordGenerator()
    return generator.detect_granular_search_needs(query_text)

# Testing directo si se ejecuta como script
if __name__ == "__main__":
    # Tests de casos problemÃ¡ticos reportados por el usuario
    test_cases = [
        "Buscar informaciÃ³n sobre 'Javier Milei' en bing y explorar los primeros resultados",
        "realizar anÃ¡lisis de datos especÃ­ficos sobre inteligencia artificial",  
        "genera informe sobre Arctic Monkeys discografÃ­a",
        "utilizar herramienta web_search para obtener datos econÃ³micos Argentina",
        "informaciÃ³n especÃ­fica sobre inflaciÃ³n Argentina 2024"
    ]
    
    print("ðŸ§ª TESTING INTELLIGENT KEYWORD GENERATOR")
    print("=" * 60)
    
    for i, test in enumerate(test_cases, 1):
        print(f"\nðŸ” TEST {i}: {test}")
        result = get_intelligent_keywords(test)
        print(f"âœ… RESULT: {result}")
        
        variants = get_multiple_search_variants(test, 2)
        print(f"ðŸ”„ VARIANTS: {variants}")
        print("-" * 40)

# Instancia global para usar en unified_web_search_tool.py
intelligent_keyword_generator = IntelligentKeywordGenerator()

def get_intelligent_keywords(query: str, num_variants: int = 1) -> str:
    """
    ðŸŽ¯ FUNCIÃ“N PRINCIPAL PARA REEMPLAZAR LAS FUNCIONES PROBLEMÃTICAS
    
    Args:
        query: Query original del usuario
        num_variants: NÃºmero de variantes (por defecto 1)
        
    Returns:
        str: Keywords inteligentes optimizados
    """
    if num_variants == 1:
        return intelligent_keyword_generator.get_intelligent_keywords(query)
    else:
        variants = intelligent_keyword_generator.get_multiple_search_variants(query, num_variants)
        return variants[0] if variants else "informaciÃ³n actualizada"

def get_multiple_search_variants(query: str, num_variants: int = 3) -> List[str]:
    """
    ðŸ“Š GENERAR MÃšLTIPLES VARIANTES PARA BÃšSQUEDAS DIVERSIFICADAS
    
    Args:
        query: Query original del usuario  
        num_variants: NÃºmero de variantes a generar
        
    Returns:
        List[str]: Lista de keywords variantes
    """
    return intelligent_keyword_generator.get_multiple_search_variants(query, num_variants)
#!/usr/bin/env python3
"""
TASKVIEW TRANSITION FIX TESTING - MITOSIS APPLICATION
Testing the specific fix for TaskView transition and consolidated task creation logic
"""

import requests
import json
import time
import logging
from datetime import datetime

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class TaskViewTransitionTester:
    def __init__(self):
        # Get backend URL from environment
        with open('/app/frontend/.env', 'r') as f:
            for line in f:
                if line.startswith('REACT_APP_BACKEND_URL='):
                    self.base_url = line.split('=')[1].strip()
                    break
            else:
                self.base_url = "https://2c2e2045-234a-4f5b-8f4e-62b51d84d8da.preview.emergentagent.com"
        
        self.api_url = f"{self.base_url}/api"
        logger.info(f"ğŸŒ Testing TaskView transition fix at: {self.api_url}")
        
        # Test results storage
        self.test_results = {
            'backend_health': {'passed': False, 'details': []},
            'task_creation': {'passed': False, 'details': []},
            'plan_generation': {'passed': False, 'details': []},
            'consolidated_logic': {'passed': False, 'details': []},
            'state_management': {'passed': False, 'details': []},
            'overall_success': False
        }

    def test_backend_health(self):
        """Test 1: Backend Health and Connectivity"""
        logger.info("ğŸ§ª TEST 1: Backend Health and Connectivity")
        
        try:
            # Test basic health endpoint
            response = requests.get(f"{self.api_url}/health", timeout=10)
            
            if response.status_code == 200:
                data = response.json()
                logger.info(f"âœ… Backend health check passed: {data.get('status')}")
                self.test_results['backend_health']['details'].append("âœ… Basic health endpoint working")
                
                # Test agent health endpoint
                agent_response = requests.get(f"{self.api_url}/agent/health", timeout=10)
                if agent_response.status_code == 200:
                    agent_data = agent_response.json()
                    logger.info(f"âœ… Agent health check passed")
                    self.test_results['backend_health']['details'].append("âœ… Agent health endpoint working")
                    self.test_results['backend_health']['passed'] = True
                else:
                    logger.warning(f"âš ï¸ Agent health endpoint returned: {agent_response.status_code}")
                    self.test_results['backend_health']['details'].append(f"âš ï¸ Agent health endpoint: {agent_response.status_code}")
                    self.test_results['backend_health']['passed'] = True  # Still pass if basic health works
                
            else:
                logger.error(f"âŒ Health check failed: {response.status_code}")
                self.test_results['backend_health']['details'].append(f"âŒ Health check failed: {response.status_code}")
                return False
                
        except Exception as e:
            logger.error(f"âŒ Health check error: {str(e)}")
            self.test_results['backend_health']['details'].append(f"âŒ Health check error: {str(e)}")
            return False
        
        return self.test_results['backend_health']['passed']

    def test_task_creation_working(self):
        """Test 2: Task Creation Working - Verify tasks can be created successfully"""
        logger.info("ğŸ§ª TEST 2: Task Creation Working")
        
        test_message = "Test TaskView transition fix"
        task_id = f"test_transition_{int(time.time())}"
        
        try:
            # Test task creation via chat endpoint (simulating frontend behavior)
            logger.info(f"  ğŸ“‹ Testing task creation with message: '{test_message}'")
            
            response = requests.post(
                f"{self.api_url}/agent/chat",
                json={
                    'message': test_message,
                    'context': {'task_id': task_id}
                },
                timeout=30
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Check if task was created successfully
                if data.get('task_id') and data.get('response'):
                    logger.info("  âœ… Task creation successful via chat endpoint")
                    self.test_results['task_creation']['details'].append("âœ… Chat endpoint creates tasks successfully")
                    
                    # Check if memory is being used (indicates proper integration)
                    if data.get('memory_used'):
                        logger.info("  âœ… Memory integration working")
                        self.test_results['task_creation']['details'].append("âœ… Memory integration active")
                    
                    self.test_results['task_creation']['passed'] = True
                    return True
                else:
                    logger.error("  âŒ Task creation response missing required fields")
                    self.test_results['task_creation']['details'].append("âŒ Response missing task_id or response")
                    
            else:
                logger.error(f"  âŒ Task creation failed: {response.status_code}")
                self.test_results['task_creation']['details'].append(f"âŒ Chat endpoint failed: {response.status_code}")
                
        except Exception as e:
            logger.error(f"  âŒ Task creation test error: {str(e)}")
            self.test_results['task_creation']['details'].append(f"âŒ Exception: {str(e)}")
        
        return False

    def test_plan_generation_working(self):
        """Test 3: Plan Generation Working - Verify backend generates plans correctly"""
        logger.info("ğŸ§ª TEST 3: Plan Generation Working")
        
        test_task = "Create a comprehensive analysis of renewable energy trends in 2025"
        task_id = f"test_plan_{int(time.time())}"
        
        try:
            # Test plan generation via initialize-task endpoint
            logger.info(f"  ğŸ“‹ Testing plan generation for: '{test_task}'")
            
            response = requests.post(
                f"{self.api_url}/agent/initialize-task",
                json={
                    'task_id': task_id,
                    'title': test_task,
                    'auto_execute': False
                },
                timeout=45
            )
            
            if response.status_code == 200:
                data = response.json()
                
                # Check if plan was generated
                plan = data.get('plan', {})
                if plan and plan.get('steps'):
                    steps = plan['steps']
                    logger.info(f"  âœ… Plan generated successfully with {len(steps)} steps")
                    self.test_results['plan_generation']['details'].append(f"âœ… Plan generated with {len(steps)} steps")
                    
                    # Check plan structure
                    if plan.get('task_type') and plan.get('complexity'):
                        logger.info("  âœ… Plan has proper structure (task_type, complexity)")
                        self.test_results['plan_generation']['details'].append("âœ… Plan structure is valid")
                    
                    # Check if steps have required fields
                    valid_steps = 0
                    for step in steps:
                        if step.get('title') and step.get('description') and step.get('tool'):
                            valid_steps += 1
                    
                    if valid_steps == len(steps):
                        logger.info("  âœ… All steps have valid structure")
                        self.test_results['plan_generation']['details'].append("âœ… All steps properly structured")
                        self.test_results['plan_generation']['passed'] = True
                        return True
                    else:
                        logger.warning(f"  âš ï¸ Only {valid_steps}/{len(steps)} steps have valid structure")
                        self.test_results['plan_generation']['details'].append(f"âš ï¸ Only {valid_steps}/{len(steps)} steps valid")
                        
                else:
                    logger.error("  âŒ No plan or steps generated")
                    self.test_results['plan_generation']['details'].append("âŒ No plan or steps generated")
                    
            else:
                logger.error(f"  âŒ Plan generation failed: {response.status_code}")
                self.test_results['plan_generation']['details'].append(f"âŒ Initialize-task failed: {response.status_code}")
                
        except Exception as e:
            logger.error(f"  âŒ Plan generation test error: {str(e)}")
            self.test_results['plan_generation']['details'].append(f"âŒ Exception: {str(e)}")
        
        return False

    def test_consolidated_task_creation_logic(self):
        """Test 4: Consolidated Task Creation Logic - Test createTaskWithMessage() function equivalent"""
        logger.info("ğŸ§ª TEST 4: Consolidated Task Creation Logic")
        
        test_cases = [
            {
                'message': 'Create a market analysis report for electric vehicles',
                'expected_type': 'task'
            },
            {
                'message': 'hola',
                'expected_type': 'casual'
            },
            {
                'message': 'Develop a comprehensive business strategy for sustainable fashion',
                'expected_type': 'task'
            }
        ]
        
        passed_tests = 0
        total_tests = len(test_cases)
        
        for i, test_case in enumerate(test_cases, 1):
            try:
                logger.info(f"  ğŸ“‹ Test case {i}: '{test_case['message']}'")
                
                response = requests.post(
                    f"{self.api_url}/agent/chat",
                    json={
                        'message': test_case['message'],
                        'context': {'task_id': f'test_consolidated_{i}_{int(time.time())}'}
                    },
                    timeout=30
                )
                
                if response.status_code == 200:
                    data = response.json()
                    
                    # Check if response is properly structured
                    required_fields = ['response', 'task_id', 'timestamp']
                    has_required = all(field in data for field in required_fields)
                    
                    if has_required:
                        logger.info(f"    âœ… Response properly structured")
                        
                        # Check if task/casual detection is working
                        mode = data.get('mode', 'unknown')
                        if test_case['expected_type'] == 'casual' and 'casual' in mode.lower():
                            logger.info(f"    âœ… Correctly identified as casual conversation")
                            passed_tests += 1
                        elif test_case['expected_type'] == 'task' and 'casual' not in mode.lower():
                            logger.info(f"    âœ… Correctly identified as task message")
                            passed_tests += 1
                        else:
                            logger.warning(f"    âš ï¸ Message type detection may be incorrect (mode: {mode})")
                            passed_tests += 0.5  # Partial credit
                            
                    else:
                        logger.error(f"    âŒ Response missing required fields")
                        
                else:
                    logger.error(f"    âŒ Request failed: {response.status_code}")
                    
            except Exception as e:
                logger.error(f"    âŒ Test case {i} error: {str(e)}")
        
        success_rate = passed_tests / total_tests
        self.test_results['consolidated_logic']['passed'] = success_rate >= 0.7
        self.test_results['consolidated_logic']['details'].append(f"âœ… {passed_tests}/{total_tests} test cases passed ({success_rate:.1%})")
        
        logger.info(f"ğŸ“Š Consolidated Logic: {passed_tests}/{total_tests} passed ({success_rate:.1%})")
        return self.test_results['consolidated_logic']['passed']

    def test_state_management_backend_support(self):
        """Test 5: State Management Backend Support - Verify backend supports proper state management"""
        logger.info("ğŸ§ª TEST 5: State Management Backend Support")
        
        try:
            # Test agent status endpoint for state information
            logger.info("  ğŸ“‹ Testing agent status for state management info...")
            
            response = requests.get(f"{self.api_url}/agent/status", timeout=15)
            
            if response.status_code == 200:
                data = response.json()
                
                # Check if status provides necessary information for frontend state management
                status_fields = ['status', 'ollama', 'tools', 'memory']
                valid_fields = 0
                
                for field in status_fields:
                    if field in data:
                        valid_fields += 1
                        logger.info(f"    âœ… Status field '{field}' present")
                    else:
                        logger.warning(f"    âš ï¸ Status field '{field}' missing")
                
                if valid_fields >= 3:
                    logger.info("  âœ… Agent status provides sufficient state information")
                    self.test_results['state_management']['details'].append("âœ… Agent status endpoint provides state info")
                    
                    # Test if we can get active tasks or similar state info
                    if 'status' in data and data['status'] == 'running':
                        logger.info("  âœ… Agent is in running state")
                        self.test_results['state_management']['details'].append("âœ… Agent running state confirmed")
                        self.test_results['state_management']['passed'] = True
                        return True
                    else:
                        logger.warning("  âš ï¸ Agent status unclear")
                        self.test_results['state_management']['details'].append("âš ï¸ Agent status unclear")
                        
                else:
                    logger.error(f"  âŒ Insufficient status fields: {valid_fields}/{len(status_fields)}")
                    self.test_results['state_management']['details'].append(f"âŒ Only {valid_fields}/{len(status_fields)} status fields present")
                    
            else:
                logger.error(f"  âŒ Agent status failed: {response.status_code}")
                self.test_results['state_management']['details'].append(f"âŒ Agent status failed: {response.status_code}")
                
        except Exception as e:
            logger.error(f"  âŒ State management test error: {str(e)}")
            self.test_results['state_management']['details'].append(f"âŒ Exception: {str(e)}")
        
        return False

    def run_all_tests(self):
        """Run all TaskView transition tests"""
        logger.info("ğŸš€ STARTING TASKVIEW TRANSITION FIX TESTING")
        logger.info("=" * 60)
        
        start_time = time.time()
        
        # Run all tests in sequence
        tests = [
            ('Backend Health', self.test_backend_health),
            ('Task Creation Working', self.test_task_creation_working),
            ('Plan Generation Working', self.test_plan_generation_working),
            ('Consolidated Task Creation Logic', self.test_consolidated_task_creation_logic),
            ('State Management Backend Support', self.test_state_management_backend_support)
        ]
        
        passed_tests = 0
        total_tests = len(tests)
        
        for test_name, test_func in tests:
            logger.info("-" * 40)
            try:
                if test_func():
                    passed_tests += 1
                    logger.info(f"âœ… {test_name}: PASSED")
                else:
                    logger.error(f"âŒ {test_name}: FAILED")
            except Exception as e:
                logger.error(f"âŒ {test_name}: EXCEPTION - {str(e)}")
        
        # Calculate overall success
        success_rate = passed_tests / total_tests
        self.test_results['overall_success'] = success_rate >= 0.8
        
        end_time = time.time()
        duration = end_time - start_time
        
        # Final summary
        logger.info("=" * 60)
        logger.info("ğŸ TASKVIEW TRANSITION TESTING COMPLETE")
        logger.info(f"ğŸ“Š Overall Results: {passed_tests}/{total_tests} tests passed ({success_rate:.1%})")
        logger.info(f"â±ï¸ Total Duration: {duration:.1f} seconds")
        logger.info(f"ğŸ¯ TaskView Transition Fix Status: {'WORKING' if self.test_results['overall_success'] else 'NEEDS ATTENTION'}")
        
        return self.test_results

def main():
    """Main test execution"""
    tester = TaskViewTransitionTester()
    results = tester.run_all_tests()
    
    # Print detailed results
    print("\n" + "=" * 60)
    print("ğŸ“‹ TASKVIEW TRANSITION FIX TEST RESULTS")
    print("=" * 60)
    
    for test_name, result in results.items():
        if test_name == 'overall_success':
            continue
            
        status = "âœ… PASSED" if result['passed'] else "âŒ FAILED"
        print(f"\n{test_name.upper().replace('_', ' ')}: {status}")
        
        for detail in result['details']:
            print(f"  {detail}")
    
    print(f"\nğŸ¯ TASKVIEW TRANSITION FIX: {'SUCCESS' if results['overall_success'] else 'NEEDS WORK'}")
    
    # Specific recommendations based on results
    if not results['overall_success']:
        print("\nğŸ”§ RECOMMENDATIONS:")
        if not results['task_creation']['passed']:
            print("  - Fix task creation endpoint issues")
        if not results['plan_generation']['passed']:
            print("  - Verify plan generation logic and schema validation")
        if not results['consolidated_logic']['passed']:
            print("  - Check consolidated task creation logic implementation")
        if not results['state_management']['passed']:
            print("  - Improve backend state management support")
    
    return 0 if results['overall_success'] else 1

if __name__ == "__main__":
    exit(main())